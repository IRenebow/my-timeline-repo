{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bf58a27-b4cb-4c8b-87f7-879e237fb2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### loading the packages\n",
    "import pandas as pd\n",
    "import os\n",
    "# import re\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from adjustText import adjust_text\n",
    "import seaborn as sns\n",
    "# from scipy.interpolate import interp1d\n",
    "# import textwrap\n",
    "# import shutil\n",
    "# import ast\n",
    "# import matplotlib\n",
    "# from collections import Counter\n",
    "# import matplotlib.patches as mpatches\n",
    "# import time\n",
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.common.keys import Keys\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.support.ui import WebDriverWait\n",
    "# from selenium.webdriver.support import expected_conditions as EC\n",
    "# from selenium.webdriver.chrome.options import Options\n",
    "# from pandas.tseries.offsets import DateOffset\n",
    "# import csv\n",
    "# import base64\n",
    "# from PIL import Image\n",
    "# import pdfkit\n",
    "# import fitz\n",
    "# import pdfplumber\n",
    "# from collections import defaultdict\n",
    "# from IPython.display import display\n",
    "# import matplotlib.dates as mdates\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35249c1e-13e9-4d12-a981-9cd818c92f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Set a global directory path\n",
    "global_directory = \"/Users/ruofeiguo/Desktop/PhD 2.0/Research/CEO_Irene\" #### Change this to your local directory!!!\n",
    "data_directory = os.path.join(global_directory, 'data')\n",
    "graph_directory = os.path.join(global_directory, 'graph')\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "os.makedirs(data_directory, exist_ok=True)\n",
    "os.makedirs(graph_directory, exist_ok=True)\n",
    "# Now you can use it globally\n",
    "os.chdir(global_directory)  # Change the current working directory to this path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22ac530f-886a-411d-9dc8-2ae9c6653c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c6d68baf5a44769acc13494351709e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntText(value=55067, description='CIK:'), IntText(value=58579, description='Partâ€¦"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######### Create input widgets\n",
    "CIK_widget = widgets.IntText(value=55067, description=\"CIK:\")\n",
    "participant_widget = widgets.IntText(value=58579, description=\"Participant ID:\")\n",
    "run_button = widgets.Button(description=\"Generate Timeline\")\n",
    "\n",
    "# This output area will display the DataFrame and the plot\n",
    "output_area = widgets.Output()\n",
    "\n",
    "def plot_compensation_timeline(CIK, participantid):\n",
    "    \"\"\"\n",
    "    Reads the vest CSV files, filters on CIK & participantid,\n",
    "    displays the combined DataFrame, and plots the timeline.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Read CSVs ---\n",
    "    df_abs = pd.read_csv(os.path.join(data_directory, 'GpbaAbs_vest.csv'))\n",
    "    df_rel = pd.read_csv(os.path.join(data_directory, 'GpbaRel_vest.csv'))\n",
    "\n",
    "    # --- Filter the DataFrames ---\n",
    "    df_abs_filtered = df_abs[(df_abs['CIK'] == CIK) & (df_abs['participantid'] == participantid)]\n",
    "    df_rel_filtered = df_rel[(df_rel['CIK'] == CIK) & (df_rel['participantid'] == participantid)]\n",
    "\n",
    "    if df_abs_filtered.empty and df_rel_filtered.empty:\n",
    "        print(f\"No data found for CIK={CIK}, participant={participantid}.\")\n",
    "        return  # nothing else to plot\n",
    "    \n",
    "    # --- Select columns and label abs/rel ---\n",
    "    columns_to_display = [\n",
    "        'CIK', 'companyName', 'metric', 'fiscalYear', \n",
    "        'grantDate', 'vestLow', 'vestHigh', 'startDate', 'endDate', 'startYear'\n",
    "    ]\n",
    "    df_abs_filtered = df_abs_filtered[columns_to_display].copy()\n",
    "    df_rel_filtered = df_rel_filtered[columns_to_display].copy()\n",
    "\n",
    "    df_abs_filtered['absRel'] = 'abs'\n",
    "    df_rel_filtered['absRel'] = 'rel'\n",
    "\n",
    "    df_combined = pd.concat([df_abs_filtered, df_rel_filtered], ignore_index=True)\n",
    "    df_combined = df_combined.sort_values(by=['metric', 'grantDate'], ascending=[True, True])\n",
    "\n",
    "    # Display the combined DataFrame (in notebook)\n",
    "    display(df_combined)\n",
    "\n",
    "    # --- Convert date columns to datetime ---\n",
    "    df_combined['grantDate'] = pd.to_datetime(df_combined['grantDate'], errors='coerce')\n",
    "    df_combined['startDate'] = pd.to_datetime(df_combined['startDate'], errors='coerce')\n",
    "    df_combined['endDate']   = pd.to_datetime(df_combined['endDate'], errors='coerce')\n",
    "\n",
    "    # --- Sort metrics by frequency ---\n",
    "    metric_counts = df_combined['metric'].value_counts(ascending=True)\n",
    "    sorted_metrics = metric_counts.index.tolist()\n",
    "\n",
    "    df_combined['metric'] = pd.Categorical(\n",
    "        df_combined['metric'], \n",
    "        categories=sorted_metrics, \n",
    "        ordered=True\n",
    "    )\n",
    "    df_combined = df_combined.sort_values(by=['metric', 'grantDate'])\n",
    "\n",
    "    # --- Set up color map, positions, etc. ---\n",
    "    palette = sns.color_palette(\"colorblind\", 10)\n",
    "    color_map = {'abs': palette[0], 'rel': palette[1]}\n",
    "\n",
    "    metric_positions = {}\n",
    "    y_positions = []\n",
    "    metric_labels = {}\n",
    "\n",
    "    current_y = 0\n",
    "    for metric in sorted_metrics:\n",
    "        metric_rows = df_combined[df_combined['metric'] == metric]\n",
    "        metric_positions[metric] = current_y\n",
    "        row_count = len(metric_rows)\n",
    "        for _ in range(row_count):\n",
    "            y_positions.append(current_y)\n",
    "            current_y += 1\n",
    "        # Center label between these bars\n",
    "        metric_labels[metric] = current_y - (row_count / 2)\n",
    "        current_y += 1  # blank row between metrics\n",
    "\n",
    "    df_combined['y_pos'] = y_positions\n",
    "\n",
    "    # --- Plot ---\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    legend_labels = {\n",
    "        'absolute, performance period': False,\n",
    "        'relative, performance period': False,\n",
    "        'Grant Date': False\n",
    "    }\n",
    "\n",
    "    for _, row in df_combined.iterrows():\n",
    "        y = row['y_pos']\n",
    "        if row['absRel'] == 'abs':\n",
    "            line_label = 'absolute, performance period'\n",
    "        else:\n",
    "            line_label = 'relative, performance period'\n",
    "\n",
    "        # performance period bar\n",
    "        if not legend_labels[line_label]:\n",
    "            ax.plot([row['startDate'], row['endDate']], [y, y], \n",
    "                    color=color_map[row['absRel']], linewidth=4, \n",
    "                    label=line_label)\n",
    "            legend_labels[line_label] = True\n",
    "        else:\n",
    "            ax.plot([row['startDate'], row['endDate']], [y, y],\n",
    "                    color=color_map[row['absRel']], linewidth=4)\n",
    "\n",
    "        # grant date marker\n",
    "        if not legend_labels['Grant Date']:\n",
    "            ax.scatter(row['grantDate'], y, color='black', marker='o', label='Grant Date')\n",
    "            legend_labels['Grant Date'] = True\n",
    "        else:\n",
    "            ax.scatter(row['grantDate'], y, color='black', marker='o')\n",
    "\n",
    "    # horizontal dashed lines to separate metrics\n",
    "    for metric, pos in metric_positions.items():\n",
    "        ax.axhline(y=pos - 1, color='gray', linestyle='dashed', alpha=0.3)\n",
    "\n",
    "    ax.set_xlabel(\"Time\")\n",
    "\n",
    "    # Title (use the first non-null companyName)\n",
    "    if df_combined['companyName'].dropna().empty:\n",
    "        title = f\"Compensation Timeline (CIK={CIK}, participant={participantid})\"\n",
    "    else:\n",
    "        title = f\"Compensation Timeline for {df_combined['companyName'].iloc[0]}\"\n",
    "    ax.set_title(title)\n",
    "\n",
    "    # y-ticks\n",
    "    ax.set_yticks(list(metric_labels.values()))\n",
    "    ax.set_yticklabels(list(metric_labels.keys()))\n",
    "\n",
    "    # Format x-axis as Year-Month\n",
    "    ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "    ax.xaxis.set_minor_locator(mdates.MonthLocator())\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # Legend ordering\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    desired_order = ['absolute, performance period', 'relative, performance period', 'Grant Date']\n",
    "    ordered_handles = [handles[labels.index(lbl)] for lbl in desired_order if lbl in labels]\n",
    "    plt.legend(ordered_handles, desired_order, loc='upper left')\n",
    "\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Optionally save figure\n",
    "    # This line saves it under timeline/companyName.jpg if you want\n",
    "    # If there's a valid companyName, otherwise fallback:\n",
    "    safe_name = title.replace(\" \", \"_\").replace(\"/\", \"_\")\n",
    "    os.makedirs(os.path.join(graph_directory, \"timeline\"), exist_ok=True)\n",
    "    plot_path = os.path.join(graph_directory, f\"timeline/{safe_name}.jpg\")\n",
    "    plt.savefig(plot_path)\n",
    "\n",
    "    print(f\"Plot saved to: {plot_path}\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def on_run_button_click(b):\n",
    "    \"\"\"\n",
    "    Clears the output area, then runs the plotting function.\n",
    "    \"\"\"\n",
    "    with output_area:\n",
    "        output_area.clear_output()\n",
    "        CIK_val = CIK_widget.value\n",
    "        participant_val = participant_widget.value\n",
    "        plot_compensation_timeline(CIK_val, participant_val)\n",
    "\n",
    "run_button.on_click(on_run_button_click)\n",
    "\n",
    "# Display the widgets & output in the notebook\n",
    "widgets.VBox([\n",
    "    widgets.HBox([CIK_widget, participant_widget]),\n",
    "    run_button,\n",
    "    output_area\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3c2806-614d-405b-afe3-363235fdf811",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
