{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bf58a27-b4cb-4c8b-87f7-879e237fb2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### loading the packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.patches as patches\n",
    "import ipywidgets as widgets\n",
    "import voila\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "35249c1e-13e9-4d12-a981-9cd818c92f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of a global directory, just use relative folders:\n",
    "# os.chdir(\"/Users/ruofeiguo/CEO Compensation/my-timeline-repo\")\n",
    "data_directory = \"data\"\n",
    "# graph_directory = \"graph\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b543138-796e-4954-b0b5-428bd7a06242",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = pd.read_csv(os.path.join(data_directory, 'SumComp.csv'))\n",
    "base['CIK'] = base['CIK'].astype(str).str.replace(r\"[^\\d]\", \"\", regex=True).astype(int)\n",
    "# # base.to_csv(os.path.join(data_directory, 'SumComp.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cb88355-b165-4e64-b019-eda84641bd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "grant = pd.read_csv(os.path.join(data_directory, 'GpbaGrant_clean.csv'))\n",
    "# grant = grant[['grantID', 'performanceGrouping']]\n",
    "# grant.to_csv(os.path.join(data_directory, 'GpbaGrant_clean.csv'), index=False)\n",
    "# print(grant.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f8b3be2-b434-4475-b659-d1649b29137d",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = pd.read_csv(os.path.join(data_directory, 'GpbaTime_vest.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "045d965e-514f-4ec3-a1de-fbd148eb0fff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of         fiscalYear  grantId            metric       size      CIK  \\\n",
      "0             2006       32          Earnings   999375.0   884887   \n",
      "1             2006       32        Individual   333125.0   884887   \n",
      "2             2007       49          Earnings   400000.0  1134538   \n",
      "3             2007       51  Operating Income  2999982.0  1134538   \n",
      "4             2007       53          Earnings   450000.0  1134538   \n",
      "...            ...      ...               ...        ...      ...   \n",
      "156946        2022  2149857    Gross Revenues  1183845.6  1571996   \n",
      "156947        2020  2150892               EPS   579637.5   937556   \n",
      "156948        2020  2150892    Gross Revenues   579637.5   937556   \n",
      "156949        2020  2150897     Profit Margin  4499943.5   937556   \n",
      "156950        2020  2150897    Gross Revenues  4499943.5   937556   \n",
      "\n",
      "        participantid   grantDate   startDate     endDate  \\\n",
      "0             33184.0  2006-01-01  2006-01-01  2007-01-01   \n",
      "1             33184.0  2006-01-01  2006-01-01  2007-01-01   \n",
      "2            155360.0  2006-12-07  2006-09-07  2007-09-07   \n",
      "3            155360.0  2007-01-01  2006-09-01  2009-09-01   \n",
      "4            155360.0  2007-01-01  2007-01-01  2008-01-01   \n",
      "...               ...         ...         ...         ...   \n",
      "156946         1942.0  2022-01-01  2022-01-01  2023-01-01   \n",
      "156947        20186.0  2020-03-12  2020-01-12  2021-01-12   \n",
      "156948        20186.0  2020-03-12  2020-01-12  2021-01-12   \n",
      "156949        20186.0  2020-03-12  2022-01-12  2023-01-12   \n",
      "156950        20186.0  2020-03-12  2022-01-12  2023-01-12   \n",
      "\n",
      "                        companyName  percentVest      value group  \n",
      "0       Royal Caribbean Cruises LTD         0.75  1332500.0    A1  \n",
      "1       Royal Caribbean Cruises LTD         0.25  1332500.0    A2  \n",
      "2                     Accenture LTD         1.00   400000.0    A1  \n",
      "3                     Accenture LTD         0.75  3999976.0    A1  \n",
      "4                     Accenture LTD         1.00   450000.0    A1  \n",
      "...                             ...          ...        ...   ...  \n",
      "156946        Dell Technologies INC         0.60  1973076.0    A3  \n",
      "156947           Masimo Corporation         0.50  1159275.0    A1  \n",
      "156948           Masimo Corporation         0.50  1159275.0    A2  \n",
      "156949           Masimo Corporation         0.50  8999887.0    A1  \n",
      "156950           Masimo Corporation         0.50  8999887.0    A2  \n",
      "\n",
      "[156951 rows x 13 columns]>\n",
      "<bound method NDFrame.head of         fiscalYear  grantId            metric       size      CIK  \\\n",
      "0             2006       32          Earnings   999375.0   884887   \n",
      "1             2006       32        Individual   333125.0   884887   \n",
      "2             2007       49          Earnings   400000.0  1134538   \n",
      "3             2007       51  Operating Income  2999982.0  1134538   \n",
      "4             2007       53          Earnings   450000.0  1134538   \n",
      "...            ...      ...               ...        ...      ...   \n",
      "156946        2022  2149857    Gross Revenues  1183845.6  1571996   \n",
      "156947        2020  2150892               EPS   579637.5   937556   \n",
      "156948        2020  2150892    Gross Revenues   579637.5   937556   \n",
      "156949        2020  2150897     Profit Margin  4499943.5   937556   \n",
      "156950        2020  2150897    Gross Revenues  4499943.5   937556   \n",
      "\n",
      "        participantid   grantDate   startDate     endDate  \\\n",
      "0             33184.0  2006-01-01  2006-01-01  2007-01-01   \n",
      "1             33184.0  2006-01-01  2006-01-01  2007-01-01   \n",
      "2            155360.0  2006-12-07  2006-09-07  2007-09-07   \n",
      "3            155360.0  2007-01-01  2006-09-01  2009-09-01   \n",
      "4            155360.0  2007-01-01  2007-01-01  2008-01-01   \n",
      "...               ...         ...         ...         ...   \n",
      "156946         1942.0  2022-01-01  2022-01-01  2023-01-01   \n",
      "156947        20186.0  2020-03-12  2020-01-12  2021-01-12   \n",
      "156948        20186.0  2020-03-12  2020-01-12  2021-01-12   \n",
      "156949        20186.0  2020-03-12  2022-01-12  2023-01-12   \n",
      "156950        20186.0  2020-03-12  2022-01-12  2023-01-12   \n",
      "\n",
      "                     companyName  percentVest      value group  \n",
      "0          Royal Caribbean Group         0.75  1332500.0    A1  \n",
      "1          Royal Caribbean Group         0.25  1332500.0    A2  \n",
      "2                  Accenture LTD         1.00   400000.0    A1  \n",
      "3                  Accenture LTD         0.75  3999976.0    A1  \n",
      "4                  Accenture LTD         1.00   450000.0    A1  \n",
      "...                          ...          ...        ...   ...  \n",
      "156946  Dell Technologies INC(2)         0.60  1973076.0    A3  \n",
      "156947        Masimo Corporation         0.50  1159275.0    A1  \n",
      "156948        Masimo Corporation         0.50  1159275.0    A2  \n",
      "156949        Masimo Corporation         0.50  8999887.0    A1  \n",
      "156950        Masimo Corporation         0.50  8999887.0    A2  \n",
      "\n",
      "[156951 rows x 13 columns]>\n"
     ]
    }
   ],
   "source": [
    "# df_comp = pd.read_csv(os.path.join(data_directory, 'GpbaAbs_vest_clean.csv'), encoding=\"latin1\")\n",
    "# print(df_comp.head)\n",
    "\n",
    "# def resolve_companyname_cik_conflicts(df_comp):\n",
    "#     # Step 1: Resolve multiple companyNames for the same CIK\n",
    "#     df_comp_sorted = df_comp.sort_values(by=['CIK', 'fiscalYear', 'companyName'], ascending=[True, False, False])\n",
    "\n",
    "#     # Select the best companyName for each CIK (latest fiscalYear, longest name)\n",
    "#     best_company_mapping = df_comp_sorted.drop_duplicates(subset=['CIK'], keep='first').set_index('CIK')['companyName']\n",
    "\n",
    "#     # Map the best companyName to all rows with that CIK\n",
    "#     df_comp['companyName'] = df_comp['CIK'].map(best_company_mapping)\n",
    "\n",
    "#     # Step 2: Resolve multiple CIKs for the same companyName\n",
    "#     cik_counts = df_comp.groupby('companyName')['CIK'].transform('nunique')  # Unique CIKs per company\n",
    "#     multiple_cik_mask = cik_counts > 1  # Identify companies linked to multiple CIKs\n",
    "\n",
    "#     # Assign ranks to CIKs within the same company\n",
    "#     df_comp['cik_rank'] = df_comp.groupby('companyName')['CIK'].rank(method='dense', ascending=True).astype(int)\n",
    "\n",
    "#     # Rename only when needed\n",
    "#     df_comp.loc[multiple_cik_mask, 'companyName'] = df_comp['companyName'] + \"(\" + df_comp['cik_rank'].astype(str) + \")\"\n",
    "\n",
    "#     # Drop the helper column\n",
    "#     df_comp.drop(columns=['cik_rank'], inplace=True)\n",
    "\n",
    "#     # Step 3: Verify One-to-One Mapping\n",
    "#     cik_to_name_counts = df_comp.groupby('CIK')['companyName'].nunique()\n",
    "#     name_to_cik_counts = df_comp.groupby('companyName')['CIK'].nunique()\n",
    "\n",
    "#     assert cik_to_name_counts.max() == 1, \"Some CIKs still map to multiple companyNames!\"\n",
    "#     assert name_to_cik_counts.max() == 1, \"Some companyNames still map to multiple CIKs!\"\n",
    "    \n",
    "#     # Ensure the shape remains the same\n",
    "#     assert df_comp.shape[0] == original_shape, \"Row count changed! No rows should be dropped.\"\n",
    "\n",
    "#     return df_comp\n",
    "\n",
    "# # Apply the function\n",
    "# original_shape = df_comp.shape[0]\n",
    "# df_final = resolve_companyname_cik_conflicts(df_comp)\n",
    "\n",
    "# # Display the final DataFrame\n",
    "# print(df_final.head)\n",
    "# df_final.to_csv(os.path.join(data_directory, 'GpbaAbs_vest_clean.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a4f6cec4-1573-4a50-a883-0e1232a60d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp = pd.read_csv(os.path.join(data_directory, 'GpbaAbs_vest_clean.csv'), encoding=\"latin1\")\n",
    "df_comp['participantid'] = df_comp['participantid'].astype(int)\n",
    "\n",
    "unique_list = (\n",
    "    df_comp[['CIK', 'companyName', 'participantid']]\n",
    "    .drop_duplicates()\n",
    "    .values\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "unique_cik = (\n",
    "    df_comp[['CIK', 'companyName']]\n",
    "    .drop_duplicates()\n",
    "    .values\n",
    "    .tolist()\n",
    ")\n",
    "cik_to_company = {cik: name for cik, name in unique_cik}\n",
    "company_to_cik = {name: cik for cik, name in unique_cik}\n",
    "\n",
    "unique_ceo = (\n",
    "    df_comp[['companyName', 'participantid']]\n",
    "    .drop_duplicates()\n",
    "    .values\n",
    "    .tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "669da12f-45ff-44af-9da6-1f09a35c2ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_rel = pd.read_csv(os.path.join(data_directory, 'GpbaRel_vest.csv'))\n",
    "# df_rel['companyName'] = df_rel['CIK'].map(cik_to_company)\n",
    "# df_rel.to_csv(os.path.join(data_directory, 'GpbaRel_vest.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "df01cf53-3856-4c56-9af5-b21eb34e532d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_combined(company_name=None, participantid=None, dis=False):\n",
    "    \"\"\"\n",
    "    Reads the CSV files, filters on company_name (substring match, case-insensitive),\n",
    "    CIK, and participantid if they are provided. Returns the combined DataFrame with\n",
    "    columns: [CIK, companyName, metric, fiscalYear, grantDate, startDate, endDate, value, absRel].\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Read CSVs ---\n",
    "    df_abs = pd.read_csv(os.path.join(data_directory, 'GpbaAbs_vest_clean.csv'))\n",
    "    df_rel = pd.read_csv(os.path.join(data_directory, 'GpbaRel_vest.csv'))\n",
    "\n",
    "    #### get CIK from unique list\n",
    "    CIK = company_to_cik[company_name]\n",
    "\n",
    "    # --- Filter the DataFrames ---\n",
    "    df_abs_filtered = df_abs[(df_abs['CIK'] == CIK) & (df_abs['participantid'] == float(participantid))]\n",
    "    df_rel_filtered = df_rel[(df_rel['CIK'] == CIK) & (df_rel['participantid'] == float(participantid))]\n",
    "\n",
    "    if df_abs_filtered.empty and df_rel_filtered.empty:\n",
    "        print(f\"No data found for CIK={CIK}, participant={participantid}.\")\n",
    "        return  # nothing else to plot\n",
    "    \n",
    "    # --- Select columns and label abs/rel ---\n",
    "    columns_to_display = [\n",
    "        'CIK', 'companyName', 'metric', 'fiscalYear', \n",
    "        'grantDate', 'startDate', 'endDate', 'size', 'percentVest', 'value', 'grantId', 'group'\n",
    "    ]\n",
    "    df_abs_filtered = df_abs_filtered[columns_to_display].copy()\n",
    "    df_rel_filtered = df_rel_filtered[columns_to_display].copy()\n",
    "\n",
    "    df_abs_filtered['absRel'] = 'abs'\n",
    "    df_rel_filtered['absRel'] = 'rel'\n",
    "\n",
    "    df_combined = pd.concat([df_abs_filtered, df_rel_filtered], ignore_index=True)\n",
    "    df_combined = df_combined.sort_values(by=['metric', 'grantDate'], ascending=[True, True])\n",
    "\n",
    "    mask = (\n",
    "        df_combined['percentVest'].isna() &\n",
    "        df_combined['size'].isna() &\n",
    "        (df_combined['metric'] == 'Unknown') &\n",
    "        (df_combined['startDate'] == df_combined['grantDate']) &\n",
    "        (df_combined['grantDate'] == df_combined['endDate'])\n",
    "    )\n",
    "    df_combined = df_combined[~mask]\n",
    "\n",
    "\n",
    "    # Display the combined DataFrame (in notebook)\n",
    "    if dis:\n",
    "        pd.set_option('display.max_rows', None)\n",
    "        pd.set_option('display.max_columns', None)\n",
    "        display(df_combined)\n",
    "\n",
    "    return df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "64596096-049a-4e5c-b78d-bddebaa30c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_compensation_timeline_by_grant(company_name, participantid, dis=False):\n",
    "    grant_intro = 'Information on metrics and their groupings:\\n'\n",
    "    \"\"\"\n",
    "    Group df_combined by 'grantId'. \n",
    "    For each group, determine distinct (grantDate, startDate, endDate) combos.\n",
    "    Plot one horizontal line per distinct combo. \n",
    "    Label the y-axis with:\n",
    "      - if there's only one distinct timeline, show the list of metrics in the group\n",
    "      - if multiple timelines exist, show separate lines, labeling each line with the relevant metrics\n",
    "    \"\"\"\n",
    "    df_combined = create_df_combined(company_name=company_name, participantid=participantid, dis=dis)\n",
    "    if df_combined.empty:\n",
    "        print(f\"No data found for company={company_name}, CIK={CIK}, participant={participantid}.\")\n",
    "        return\n",
    "\n",
    "    # Just in case, ensure these are datetimes\n",
    "    df_combined['grantDate'] = pd.to_datetime(df_combined['grantDate'], errors='coerce')\n",
    "    df_combined['startDate'] = pd.to_datetime(df_combined['startDate'], errors='coerce')\n",
    "    df_combined['endDate']   = pd.to_datetime(df_combined['endDate'], errors='coerce')\n",
    "\n",
    "    CIK = company_to_cik[company_name]\n",
    "    \n",
    "    # --- Retrieve base salary data ---\n",
    "    if pd.isna(CIK):  # If company_name is used, map it to CIK\n",
    "        CIK = df_combined['CIK'].iloc[0] if not df_combined.empty else None\n",
    "\n",
    "    base_filtered = base[(base['CIK'] == CIK) & (base['participantid'] == int(participantid))]\n",
    "    time_filtered = time[(time['CIK'] == CIK) & (time['participantid'] == int(participantid))]\n",
    "\n",
    "    # Convert fiscalYear to integer for sorting\n",
    "    base_filtered.loc[:,'FiscalYear'] = pd.to_numeric(base_filtered['FiscalYear'], errors='coerce')\n",
    "    \n",
    "    # --- Compute the minimum value for scaling line thickness ---\n",
    "    max_value = pd.concat([df_combined['size'], base_filtered['salary'], base_filtered['stockAwards'], base_filtered['optionAwards'], time_filtered['grantDateFV']], axis=0).dropna().max()\n",
    "\n",
    "    # Group by grantId\n",
    "    grouped = df_combined.groupby('grantId', dropna=False)\n",
    "    group_grant_dates = {grantId: sub_df['grantDate'].min() for grantId, sub_df in grouped}\n",
    "    sorted_groups = sorted(group_grant_dates.items(), key=lambda x: x[1])\n",
    "\n",
    "    # Prepare the figure\n",
    "    fig_width = 12  # Keep a fixed width\n",
    "    fig_height = max(6, (len(grouped)+1) * 0.5)  # Scale height based on number of items\n",
    "    fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "\n",
    "    # For coloring, reuse your color scheme if you want\n",
    "    # palette = sns.color_palette(\"colorblind\", 10)\n",
    "    color_map = {'abs': '#4C72B0', 'rel': '#F4A261'}\n",
    "    \n",
    "    # We'll keep track of the y-position for each group\n",
    "    current_y = 10\n",
    "    y_positions = []\n",
    "    y_labels = []\n",
    "\n",
    "    # Track legend entries\n",
    "    legend_labels = {\n",
    "        'absolute, performance period': False,\n",
    "        'relative, performance period': False,\n",
    "        'Grant Date': False,\n",
    "        'Non-performance-based': False,\n",
    "        'Time-based': False\n",
    "    }\n",
    "\n",
    "    # --- Plot Base Salary ---\n",
    "    max_salary_award = 0 if base_filtered['salary'].dropna().empty else max(20 * base_filtered['salary'].dropna().max() / max_value, 0.3)\n",
    "    max_stock_award = 0 if base_filtered['stockAwards'].dropna().empty else max(20 * base_filtered['stockAwards'].dropna().max() / max_value, 0.3)\n",
    "    max_option_award = 0 if base_filtered['optionAwards'].dropna().empty else max(20 * base_filtered['optionAwards'].dropna().max() / max_value, 0.3)\n",
    "    base_salary_y = current_y\n",
    "    stock_y = base_salary_y + max_salary_award/2 + 4 + max_stock_award/2\n",
    "    option_y = stock_y + max_stock_award/2 + 4 + max_option_award/2\n",
    "    ax.axhline(y=base_salary_y + max_salary_award/2 + 2, color='gray', linestyle='dashed', alpha=0.3)\n",
    "    ax.axhline(y=stock_y + max_stock_award/2 + 2, color='gray', linestyle='dashed', alpha=0.3)\n",
    "    for _, row in base_filtered.iterrows():\n",
    "        fiscal_year = int(row['FiscalYear'])\n",
    "        salary_value = row['salary']\n",
    "        salary_height = 0\n",
    "        if pd.notna(salary_value):\n",
    "            height = max(20 * salary_value / max_value, 1)\n",
    "            # Create a rectangle for base salary\n",
    "            base_salary_rect = patches.Rectangle(\n",
    "                (pd.Timestamp(f\"{fiscal_year}-01-01\"), base_salary_y - height / 2),  # (x, y) position\n",
    "                pd.Timedelta(days=365),  # Width covering the full year\n",
    "                height,  # Height scaled to salary value\n",
    "                color='black',\n",
    "                label='Non-performance-based'\n",
    "            )\n",
    "            \n",
    "            ax.add_patch(base_salary_rect)  # Add rectangle to the plot\n",
    "\n",
    "            legend_labels['Non-performance-based'] = True\n",
    "\n",
    "        stock_value = row['stockAwards']\n",
    "        if pd.notna(stock_value):\n",
    "            height = max(20 * stock_value / max_value, 1)\n",
    "            # Create a rectangle for base salary\n",
    "            stock_rect = patches.Rectangle(\n",
    "                (pd.Timestamp(f\"{fiscal_year}-01-01\"), stock_y - height / 2),  # (x, y) position\n",
    "                pd.Timedelta(days=365),  # Width covering the full year\n",
    "                height,  # Height scaled to salary value\n",
    "                color='black',\n",
    "                label='Non-performance-based'\n",
    "            )\n",
    "            \n",
    "            ax.add_patch(stock_rect)  # Add rectangle to the plot\n",
    "            legend_labels['Non-performance-based'] = True\n",
    "\n",
    "        option_value = row['optionAwards']\n",
    "        if pd.notna(option_value):\n",
    "            height = max(20 * option_value / max_value, 1)\n",
    "            # Create a rectangle for base salary\n",
    "            option_rect = patches.Rectangle(\n",
    "                (pd.Timestamp(f\"{fiscal_year}-01-01\"), option_y - height / 2),  # (x, y) position\n",
    "                pd.Timedelta(days=365),  # Width covering the full year\n",
    "                height,  # Height scaled to salary value\n",
    "                color='black',\n",
    "                label='Non-performance-based'\n",
    "            )\n",
    "            \n",
    "            ax.add_patch(option_rect)  # Add rectangle to the plot\n",
    "            legend_labels['Non-performance-based'] = True\n",
    "\n",
    "    current_y = option_y + max_option_award/2 + 2\n",
    "    # --- Plot Time-Based ---\n",
    "    ax.axhline(y=current_y, color='gray', linestyle='dashed', alpha=0.3)\n",
    "    # print(time_filtered)\n",
    "    time_filtered = time_filtered.sort_values(by='grantDate')\n",
    "    time_y = current_y\n",
    "    current_y += 2\n",
    "    all_nan = time_filtered['grantDateFV'].isna().all()\n",
    "    \n",
    "    for _, row in time_filtered.iterrows():\n",
    "        grantDateFV = row['grantDateFV']\n",
    "        sDate = pd.to_datetime(row['startDate'])\n",
    "        eDate = pd.to_datetime(row['endDate'])\n",
    "        gDate = pd.to_datetime(row['grantDate'])\n",
    "        oops = False\n",
    "        if sDate == eDate:\n",
    "            eDate += pd.Timedelta(days=10)\n",
    "            oops = True\n",
    "        \n",
    "        if pd.notna(grantDateFV):\n",
    "            height = max(20 * grantDateFV / max_value, 1)\n",
    "            # Create a rectangle for base salary\n",
    "            rect = patches.Rectangle(\n",
    "                (sDate, current_y),  # (x, y) position\n",
    "                eDate - sDate,  # width\n",
    "                height,  # height in data units\n",
    "                color='#E9C46A',\n",
    "                label='Time-based'\n",
    "            )\n",
    "            \n",
    "            ax.add_patch(rect)  # Add rectangle to the plot\n",
    "            if oops == True:\n",
    "                ax.scatter(gDate, current_y+height/2, color='black', marker='o', s=6, label=\"Grant Date\" if not legend_labels['Grant Date'] else \"\", zorder=0)\n",
    "            else:\n",
    "                ax.scatter(gDate, current_y+height/2, color='black', marker='o', s=6, label=\"Grant Date\" if not legend_labels['Grant Date'] else \"\", zorder=5)\n",
    "            legend_labels['Time-based'] = True\n",
    "            legend_labels['Grant Date'] = True\n",
    "\n",
    "            current_y += height+2\n",
    "        else:\n",
    "            ax.hlines(\n",
    "                y=current_y,\n",
    "                xmin=sDate,\n",
    "                xmax=eDate,\n",
    "                color=\"#E9C46A\",\n",
    "                linestyle=\"dashed\",\n",
    "                linewidth=1.5,  # Adjust thickness of dashed line\n",
    "                label='Time-based' if all_nan else \"\"\n",
    "            )\n",
    "            if oops == True:\n",
    "                ax.scatter(gDate, current_y, color='black', marker='o', s=6, label=\"Grant Date\" if not legend_labels['Grant Date'] else \"\", zorder=0)\n",
    "            else:\n",
    "                ax.scatter(gDate, current_y, color='black', marker='o', s=6, label=\"Grant Date\" if not legend_labels['Grant Date'] else \"\", zorder=5)\n",
    "            legend_labels['Time-based'] = True\n",
    "            legend_labels['Grant Date'] = True\n",
    "            current_y += 2\n",
    "\n",
    "    current_y += 2\n",
    "    time_y = (current_y + time_y)/2\n",
    "        \n",
    "\n",
    "    # --- Plot Performance-Based ---\n",
    "    sorted_grant_ids = sorted(grouped.groups.keys(), key=lambda x: group_grant_dates[x])\n",
    "\n",
    "    for grant_id in sorted_grant_ids:\n",
    "        performance_grouping = grant.loc[grant['grantID'] == grant_id, 'performanceGrouping']\n",
    "    \n",
    "        # If grant_id is found, get the first matching value\n",
    "        performance_grouping = performance_grouping.iloc[0] if not performance_grouping.empty else None\n",
    "        \n",
    "        ax.axhline(y=current_y, color='gray', linestyle='dashed', alpha=0.3)\n",
    "        # old_y = current_y\n",
    "        group_df = grouped.get_group(grant_id)  # Retrieve the actual DataFrame\n",
    "        label_for_group = (f\"grant {grant_id}\" if pd.notna(grant_id) else \"unknown grant\") \n",
    "        group_df = group_df.copy()\n",
    "        group_df['metric_absrel'] = group_df['metric']+group_df['absRel']\n",
    "\n",
    "        novalue = False\n",
    "        if group_df['value'].isna().all():\n",
    "            novalue = True\n",
    "        else:\n",
    "            first_value = group_df['value'].iloc[0] if not group_df['value'].isna().all() else min_value\n",
    "            total_height = max(20 * (first_value / max_value) if max_value else 20,1)\n",
    "            # 1) Check if percentVest has NaNs\n",
    "            if group_df['percentVest'].isna().any():\n",
    "                use_count_based = True\n",
    "                total_count = len(group_df)\n",
    "                group_df['computedVest'] = total_height / total_count  # Equal height for all rows\n",
    "            else:\n",
    "                use_count_based = False\n",
    "                total_percentVest = group_df['percentVest'].sum()\n",
    "                if total_percentVest == 0 or pd.isna(total_percentVest):\n",
    "                    total_percentVest = 1  # Avoid division by zero\n",
    "                group_df['computedVest'] = np.maximum(group_df['percentVest'] / total_percentVest * total_height, 0.8)\n",
    "        \n",
    "        # Identify distinct combos within this group\n",
    "        # Step 1: Create a unique schedule for each metric\n",
    "        # Convert schedule into a tuple set per metric\n",
    "        schedule_dict = {}\n",
    "        for metric, group in group_df.groupby('metric_absrel'):\n",
    "            unique_schedule = group[['grantDate', 'startDate', 'endDate']].drop_duplicates()\n",
    "            schedule = tuple(unique_schedule.apply(tuple, axis=1))\n",
    "            schedule_dict[metric] = schedule\n",
    "        \n",
    "        # Step 2: Group metrics by identical schedules\n",
    "        schedule_to_metrics = {}\n",
    "        for metric, schedule in schedule_dict.items():\n",
    "            if schedule in schedule_to_metrics:\n",
    "                schedule_to_metrics[schedule].append(metric)\n",
    "            else:\n",
    "                schedule_to_metrics[schedule] = [metric]\n",
    "        \n",
    "        # Step 3: Assign group labels to metrics\n",
    "        metric_to_group = {}\n",
    "        for group_idx, (schedule, metrics) in enumerate(schedule_to_metrics.items(), start=1):\n",
    "            for metric in metrics:\n",
    "                metric_to_group[metric] = f\"Group_{group_idx}\"\n",
    "        \n",
    "        # Step 4: Add group information back to the original DataFrame\n",
    "        group_df = group_df.copy()\n",
    "        group_df['metric_group'] = group_df['metric_absrel'].map(metric_to_group)\n",
    "        # print(group_df)\n",
    "\n",
    "        further_groups = group_df.groupby(['metric_group'], dropna=False)\n",
    "        \n",
    "        # If only 1 distinct timeline, we label the y-axis with all metrics from the entire group\n",
    "        # else, we label each timeline line with its metrics\n",
    "        if len(further_groups) == 1:\n",
    "            \n",
    "            # print(grant_id,1)\n",
    "            # There's just one combo => we can directly get that\n",
    "            metric_group, metric_df = list(further_groups)[0]\n",
    "            combo_groups = metric_df.groupby(['grantDate', 'startDate', 'endDate'], dropna=False)\n",
    "\n",
    "            sorted_metrics = list(set(metric_df['metric'].tolist()[::-1]))\n",
    "            metric_label = \", \".join(sorted_metrics) if sorted_metrics else \"No Metric\"\n",
    "\n",
    "            grant_intro += f'Grant ID: {grant_id}\\nGrouping: {performance_grouping}\\nMetrics: {metric_label}\\n'\n",
    "\n",
    "            current_y += 6\n",
    "            base_y = current_y\n",
    "            \n",
    "            for (gDate, sDate, eDate), sub_df in combo_groups:\n",
    "                # Plot one line\n",
    "                if novalue:\n",
    "                    # print(grant_id,'novalue')\n",
    "                    color = color_map.get(row['absRel'], 'gray')\n",
    "                    ax.hlines(\n",
    "                        y=current_y,\n",
    "                        xmin=sDate,\n",
    "                        xmax=eDate,\n",
    "                        color=color,\n",
    "                        linestyle=\"dashed\",\n",
    "                        linewidth=1.5  # Adjust thickness of dashed line\n",
    "                    )\n",
    "                    ax.scatter(gDate, current_y, color='black', marker='o', s=20, label=\"Grant Date\" if not legend_labels['Grant Date'] else \"\", zorder=5)\n",
    "                    legend_labels['Grant Date'] = True\n",
    "                else:\n",
    "                    sub_df = sub_df.sort_values(by=['absRel', 'computedVest'], ascending=[False, True])\n",
    "                    # 3) Compute the vertical stacking based on computedVest\n",
    "                    start_y = current_y\n",
    "                    for _, row in sub_df.iterrows():\n",
    "                        height = row['computedVest']\n",
    "                        color = color_map.get(row['absRel'], 'gray')\n",
    "        \n",
    "                        line_label = 'absolute, performance period' if row['absRel'] == 'abs' else 'relative, performance period'\n",
    "\n",
    "                        # print(grant_id,metric,sDate,eDate,start_y)\n",
    "                        # Create a rectangle patch instead of using `ax.plot`\n",
    "                        rect = patches.Rectangle(\n",
    "                            (sDate, start_y),  # (x, y) position\n",
    "                            eDate - sDate,  # width\n",
    "                            height,  # height in data units\n",
    "                            facecolor=color,\n",
    "                            edgecolor=None,  # Optional: add border for better visibility\n",
    "                            linewidth=0.2,  # Keep a thin border\n",
    "                            label=line_label if not legend_labels[line_label] else None\n",
    "                        )\n",
    "                        \n",
    "                        ax.add_patch(rect)  # Add rectangle to the plot\n",
    "        \n",
    "                        # Draw a dashed line between stacked rectangles (except for the last one)\n",
    "                        if _ != sub_df.index[-1]:  \n",
    "                            ax.hlines(\n",
    "                                y=start_y + height,  # Position at top of current rectangle\n",
    "                                xmin=sDate,\n",
    "                                xmax=eDate,\n",
    "                                color=\"white\",\n",
    "                                linestyle=\"dashed\",\n",
    "                                linewidth=0.5  # Adjust thickness of dashed line\n",
    "                            )\n",
    "        \n",
    "                        \n",
    "                        legend_labels[line_label] = True  # Mark legend entry as used\n",
    "                \n",
    "                        # Move up to stack the next segment\n",
    "                        start_y += height  # Ensure consistent stacking in data units\n",
    "                \n",
    "                    # Plot the grant date marker\n",
    "                    ax.scatter(gDate, (current_y + start_y) / 2, color='black', marker='o', s=6, label=\"Grant Date\" if not legend_labels['Grant Date'] else \"\", zorder=5)\n",
    "                    legend_labels['Grant Date'] = True\n",
    "                    current_y = start_y+3\n",
    "    \n",
    "            # We'll label the entire group's y-tick with the list of metrics\n",
    "            y_positions.append((base_y+ current_y)/2)\n",
    "            y_labels.append(f\"{label_for_group}\")\n",
    "\n",
    "            current_y += 6\n",
    "        \n",
    "        else:\n",
    "            # print(grant_id,0)\n",
    "            # Multiple distinct combos => each timeline gets its own line\n",
    "            # We'll label each line with the relevant metrics\n",
    "            lines_in_group = 0\n",
    "            current_y += 6\n",
    "            count = 0\n",
    "            grant_intro += f'Grant ID: {grant_id}\\nGrouping: {performance_grouping}\\n'\n",
    "            \n",
    "            for metric_group, metric_df in further_groups:\n",
    "                base_y = current_y\n",
    "                count += 1\n",
    "                if count >1:\n",
    "                    current_y += 6\n",
    "                    ax.axhline(y=current_y, color='gray', linestyle='dashed', alpha=0.3)\n",
    "                    current_y += 6\n",
    "                base_y = current_y\n",
    "                    \n",
    "                combo_groups = metric_df.groupby(['grantDate', 'startDate', 'endDate'], dropna=False)\n",
    "\n",
    "                sorted_metrics = list(set(metric_df['metric'].tolist()[::-1]))\n",
    "                \n",
    "                metric_label = \", \".join(sorted_metrics) if sorted_metrics else \"No Metric\"\n",
    "    \n",
    "                grant_intro += f'  {grant_id}({count}) metrics: {metric_label}\\n'\n",
    "    \n",
    "                \n",
    "                for (gDate, sDate, eDate), sub_df in combo_groups:\n",
    "                    # Plot one line\n",
    "                    if novalue:\n",
    "                        color = color_map.get(row['absRel'], 'gray')\n",
    "                        ax.hlines(\n",
    "                            y=current_y,\n",
    "                            xmin=sDate,\n",
    "                            xmax=eDate,\n",
    "                            color=color,\n",
    "                            linestyle=\"dashed\",\n",
    "                            linewidth=1.5  # Adjust thickness of dashed line\n",
    "                        )\n",
    "                        ax.scatter(gDate, current_y, color='black', marker='o', s=20, label=\"Grant Date\" if not legend_labels['Grant Date'] else \"\", zorder=5)\n",
    "                        legend_labels['Grant Date'] = True\n",
    "                    else:\n",
    "                        sub_df = sub_df.sort_values(by=['absRel', 'computedVest'], ascending=[False, True])\n",
    "                        # 3) Compute the vertical stacking based on computedVest\n",
    "                        start_y = current_y\n",
    "                        for _, row in sub_df.iterrows():\n",
    "                            height = row['computedVest']\n",
    "                            color = color_map.get(row['absRel'], 'gray')\n",
    "            \n",
    "                            line_label = 'absolute, performance period' if row['absRel'] == 'abs' else 'relative, performance period'\n",
    "            \n",
    "                            # Create a rectangle patch instead of using `ax.plot'\n",
    "                            rect = patches.Rectangle(\n",
    "                                (sDate, start_y),  # (x, y) position\n",
    "                                eDate - sDate,  # width\n",
    "                                height,  # height in data units\n",
    "                                facecolor=color,\n",
    "                                edgecolor=None,  # Optional: add border for better visibility\n",
    "                                linewidth=0.2,  # Keep a thin border\n",
    "                                label=line_label if not legend_labels[line_label] else None\n",
    "                            )\n",
    "                            \n",
    "                            ax.add_patch(rect)  # Add rectangle to the plot\n",
    "            \n",
    "                            # Draw a dashed line between stacked rectangles (except for the last one)\n",
    "                            if _ != sub_df.index[-1]:\n",
    "                                ax.hlines(\n",
    "                                    y=start_y + height,  # Position at top of current rectangle\n",
    "                                    xmin=sDate,\n",
    "                                    xmax=eDate,\n",
    "                                    color=\"white\",\n",
    "                                    linestyle=\"dashed\",\n",
    "                                    linewidth=0.5  # Adjust thickness of dashed line\n",
    "                                )\n",
    "            \n",
    "                            \n",
    "                            legend_labels[line_label] = True  # Mark legend entry as used\n",
    "                    \n",
    "                            # Move up to stack the next segment\n",
    "                            start_y += height  # Ensure consistent stacking in data units\n",
    "                    \n",
    "                        # Plot the grant date marker\n",
    "                        ax.scatter(gDate, (current_y + start_y) / 2, color='black', marker='o', s=6, label=\"Grant Date\" if not legend_labels['Grant Date'] else \"\", zorder=5)\n",
    "                        legend_labels['Grant Date'] = True\n",
    "                        current_y = start_y+3\n",
    "                        \n",
    "                # We'll label the entire group's y-tick with the list of metrics\n",
    "                y_positions.append((base_y+ current_y)/2)\n",
    "                y_labels.append(f\"{label_for_group}({count})\")\n",
    "    \n",
    "            current_y += 6\n",
    "\n",
    "    # Decorate axes\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    ax.set_ylabel(\"Grant-level grouping\")\n",
    "\n",
    "    # Format x-axis as Year-Month\n",
    "    ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "    ax.xaxis.set_minor_locator(mdates.MonthLocator())\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # y-ticks\n",
    "    ax.set_yticks(y_positions + [time_y, option_y, stock_y, base_salary_y])\n",
    "    ax.set_yticklabels(y_labels + [\"Time-Based Awards\", \"Option Awards\", \"Stock Awards\", \"Base Salary\"])\n",
    "\n",
    "    ax.grid(axis='x', linestyle='--', alpha=0.6)\n",
    "\n",
    "    # --- Ensure Proper Legend ---\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    desired_order = ['absolute, performance period', 'relative, performance period', 'Grant Date', 'Non-performance-based', 'Time-based']\n",
    "    final_labels = [lbl for lbl in desired_order if legend_labels.get(lbl, False)]\n",
    "    ordered_handles = [handles[labels.index(lbl)] for lbl in final_labels if lbl in labels]\n",
    "    ax.legend(ordered_handles, final_labels, loc='upper left')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.title(f\"Grant-Level Timeline for {df_combined['companyName'].iloc[0]}, CEO {participantid}\")\n",
    "    plt.show()\n",
    "    print(grant_intro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "39161142-fe96-4f70-b8c9-87967ba0f262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7063bdbf24cf4d459aaab94aa5e888b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<h1 style='text-align: center;'>Visualizing CEO Compensation</h1>\"), HBox(children=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32c70502808345feab746ec1ebb523c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build sets of all names, all CIKs:\n",
    "all_company_names = sorted({nm for (_, nm, _) in unique_list})\n",
    "all_ciks = sorted({c for (c, _, _) in unique_list})\n",
    "all_ceos = sorted({p for (_, _, p) in unique_list})\n",
    "# Create an Output widget to capture logs\n",
    "debug_output = widgets.Output()\n",
    "\n",
    "def filter_company_names(substring):\n",
    "    \"\"\"Return a list of company names containing 'substring' (case-insensitive).\"\"\"\n",
    "    s_lower = substring.lower()\n",
    "    return [n for n in all_company_names if s_lower in n.lower()]\n",
    "\n",
    "def filter_ceos(substring):\n",
    "    \"\"\"Return a list of CEOs (as strings) containing 'substring'.\"\"\"\n",
    "    return [str(p) for p in all_ceos if substring in str(p)]\n",
    "\n",
    "def names_for_ceo(ceo_name):\n",
    "    \"\"\"All company names that match the given CIK in company_list.\"\"\"\n",
    "    try:\n",
    "        return sorted({\n",
    "            n for (n, ceo) in unique_ceo if ceo == ceo_name\n",
    "        })\n",
    "    except ValueError:\n",
    "        return []\n",
    "\n",
    "def ceos_for_name(company_name):\n",
    "    \"\"\"All CEO names that match the given CIK in ceo_list.\"\"\"\n",
    "    try:\n",
    "        matched_ceos = sorted({\n",
    "            ceo for (n, ceo) in unique_ceo if n == company_name\n",
    "        })\n",
    "        return matched_ceos\n",
    "    except ValueError:\n",
    "        with debug_output:\n",
    "            print(f\"Error: Invalid company_name.\")  # Debugging log\n",
    "        return []  # Ensure function does not break\n",
    "\n",
    "def on_company_typed(change):\n",
    "    if change['name'] == 'value':\n",
    "        typed = change['new']\n",
    "        # Filter company suggestions\n",
    "        company_widget.options = [\n",
    "            n for n in all_company_names \n",
    "            if typed.lower() in n.lower()\n",
    "        ]\n",
    "        \n",
    "        if typed in all_company_names:\n",
    "            matched_ceos = ceos_for_name(typed)\n",
    "            matched_ceos = [str(ceo) for ceo in matched_ceos]\n",
    "            participant_widget.options = matched_ceos\n",
    "\n",
    "            # If the current typed CIK isn't in matched_ciks, clear the CIK\n",
    "            if participant_widget.value not in matched_ceos:\n",
    "                participant_widget.value = \"\"  # Clear if mismatch\n",
    "        else:\n",
    "            # Not a finalized name => you could restore full CIK list or partial filter\n",
    "            participant_widget.value = \"\"\n",
    "            participant_widget.options = all_ceos\n",
    "            pass\n",
    "\n",
    "def on_ceo_typed(change):\n",
    "    if change['name'] == 'value':\n",
    "        typed = change['new'].strip()\n",
    "        participant_widget.options = filter_ceos(typed)\n",
    "        known_ceos = [str(p) for p in all_ceos]\n",
    "        \n",
    "        # If typed is exactly one known CIK:\n",
    "        if typed in known_ciks:\n",
    "            # Show only the matched company name(s)\n",
    "            matched_names = names_for_ceo(typed)\n",
    "            company_widget.options = matched_names\n",
    "\n",
    "            # If the current typed company isn't in matched_names, clear the company\n",
    "            if company_widget.value not in matched_names:\n",
    "                company_widget.value = \"\"\n",
    "        else:\n",
    "            # Not a finalized CIK => you could restore full name list or partial filter\n",
    "            company_widget.value = \"\"\n",
    "            company_widget.options = all_company_names\n",
    "\n",
    "def on_run_button_click(b):\n",
    "    \"\"\"\n",
    "    Clears the output area, then runs the plotting function.\n",
    "    \"\"\"\n",
    "    with output_area:\n",
    "        output_area.clear_output()\n",
    "        \n",
    "        company_val = company_widget.value\n",
    "        participant_val = participant_widget.value\n",
    "\n",
    "        # Now call your timeline function(s)\n",
    "        plot_compensation_timeline_by_grant(company_val, participant_val, False)\n",
    "\n",
    "# --- Create dynamic Comboboxes for Company & CIK ---\n",
    "company_widget = widgets.Combobox(\n",
    "    placeholder='Type a company name...',\n",
    "    options=all_company_names,\n",
    "    description='Company:'\n",
    ")\n",
    "company_widget.value = \"\"  # your existing default\n",
    "\n",
    "participant_widget = widgets.Combobox(\n",
    "    placeholder='Type a CEO ID...',\n",
    "    options=[str(p) for p in all_ceos],\n",
    "    description='CEO ID:'\n",
    ")\n",
    "participant_widget.value = \"\"  # your existing default\n",
    "\n",
    "run_button = widgets.Button(description=\"Generate Timeline\")\n",
    "output_area = widgets.Output()\n",
    "\n",
    "company_widget.observe(on_company_typed, names='value')\n",
    "participant_widget.observe(on_ceo_typed, names='value')\n",
    "# Create a title widget\n",
    "title_widget = widgets.HTML(\n",
    "    value=\"<h1 style='text-align: center;'>Visualizing CEO Compensation</h1>\"\n",
    ")\n",
    "\n",
    "run_button.on_click(on_run_button_click)\n",
    "\n",
    "# Create the Clear button\n",
    "clear_button = widgets.Button(description=\"Clear\", button_style='warning')\n",
    "\n",
    "# Function to clear input fields\n",
    "def on_clear_button_click(b):\n",
    "    company_widget.value = \"\"\n",
    "    participant_widget.value = \"\"\n",
    "\n",
    "# Attach event to Clear button\n",
    "clear_button.on_click(on_clear_button_click)\n",
    "\n",
    "# Display the widgets & output in the notebook\n",
    "display(\n",
    "    widgets.VBox([\n",
    "        title_widget,  # Add the title at the top\n",
    "        widgets.HBox([company_widget, participant_widget]),\n",
    "        widgets.HBox([run_button, clear_button]),\n",
    "        output_area\n",
    "    ])\n",
    ")\n",
    "display(debug_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a360a4b-5a8b-4bb4-be2c-80577c4b73de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92f0ad7-f5eb-48e1-a2c1-d969a7371f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
