{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bf58a27-b4cb-4c8b-87f7-879e237fb2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### loading the packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as mdates\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import voila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35249c1e-13e9-4d12-a981-9cd818c92f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of a global directory, just use relative folders:\n",
    "data_directory = \"data\"\n",
    "graph_directory = \"graph\"\n",
    "\n",
    "# Ensure these folders exist (Binder will create them fresh each session)\n",
    "# os.makedirs(data_directory, exist_ok=True)\n",
    "# os.makedirs(graph_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7f859524-bb17-4e87-be5f-33512a16837f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# df_rel = pd.read_csv(os.path.join(data_directory, 'GpbaRel_vest.csv'))\n",
    "# # for col in df_abs.columns:\n",
    "#     # print(col)\n",
    "# df_rel['value'] = df_rel[['nonEquityTarget', 'grantDateFV']].bfill(axis=1).iloc[:, 0]\n",
    "# columns_to_keep = ['fiscalYear', 'grantId', 'metric', 'size', 'CIK', 'participantid', 'grantDate', 'startDate', 'endDate', 'companyName']\n",
    "# df_rel['size'] = df_rel['value']*df_rel['percentVest']\n",
    "# df_rel = df_rel[columns_to_keep]\n",
    "# df_rel.to_csv(os.path.join(data_directory, 'GpbaRel_vest_clean.csv'), index=False)\n",
    "# # df_rel.to_csv(os.path.join(data_directory, 'GpbaRel_vest.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2207b03-861f-4ae0-a8e0-be4f317db2eb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# df_abs = pd.read_csv(os.path.join(data_directory, 'GpbaAbs_vest.csv'))\n",
    "# # for col in df_abs.columns:\n",
    "#     # print(col)\n",
    "# df_abs['value'] = df_abs[['nonEquityTarget', 'grantDateFV']].bfill(axis=1).iloc[:, 0]\n",
    "# columns_to_keep = ['fiscalYear', 'grantId', 'metric', 'size', 'CIK', 'participantid', 'grantDate', 'startDate', 'endDate', 'companyName']\n",
    "# df_abs['size'] = df_abs['value']*df_abs['percentVest']\n",
    "# df_abs = df_abs[columns_to_keep]\n",
    "# df_abs.to_csv(os.path.join(data_directory, 'GpbaAbs_vest_clean.csv'), index=False)\n",
    "# # df_abs.to_csv(os.path.join(data_directory, 'GpbaAbs_vest.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b543138-796e-4954-b0b5-428bd7a06242",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = pd.read_csv(os.path.join(data_directory, 'SumComp.csv'))\n",
    "base['CIK'] = base['CIK'].astype(str).str.replace(r\"[^\\d]\", \"\", regex=True).astype(int)\n",
    "# # base.to_csv(os.path.join(data_directory, 'SumComp.csv'), index=False)\n",
    "# print(base.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4f6cec4-1573-4a50-a883-0e1232a60d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp = pd.read_csv(os.path.join(data_directory, 'GpbaAbs_vest_clean.csv'), encoding=\"latin1\")\n",
    "df_comp['CIK'] = df_comp['CIK'].astype(str).str.replace(r\"[^\\d]\", \"\", regex=True).astype(int)\n",
    "# # # 1) Check for multiple companyNames per CIK\n",
    "# # cik_name_counts = df_comp.groupby('CIK')['companyName'].nunique()\n",
    "# # ciks_multiple_names = cik_name_counts[cik_name_counts > 1].index\n",
    "\n",
    "# # # if len(ciks_multiple_names) > 0:\n",
    "# # #     print(\"CIKs that map to multiple companyName values:\")\n",
    "# # #     for bad_cik in ciks_multiple_names:\n",
    "# # #         # Print all rows for this CIK, showing the different companyNames\n",
    "# # #         subset = df_comp[df_comp['CIK'] == bad_cik][['CIK', 'companyName']].drop_duplicates()\n",
    "# # #         print(subset)\n",
    "# # # else:\n",
    "# # #     print(\"No CIK maps to multiple companyName values.\")\n",
    "\n",
    "# # # print(\"----\")\n",
    "\n",
    "# # # 2) Check for multiple CIKs per companyName\n",
    "# # name_cik_counts = df_comp.groupby('companyName')['CIK'].nunique()\n",
    "# # names_multiple_ciks = name_cik_counts[name_cik_counts > 1].index\n",
    "\n",
    "# # if len(names_multiple_ciks) > 0:\n",
    "# #     print(\"companyName values that map to multiple CIKs:\")\n",
    "# #     for bad_name in names_multiple_ciks:\n",
    "# #         # Print all rows for this companyName, showing the different CIKs\n",
    "# #         subset = df_comp[df_comp['companyName'] == bad_name][['CIK', 'companyName']].drop_duplicates()\n",
    "# #         print(subset)\n",
    "# # else:\n",
    "# #     print(\"No companyName maps to multiple CIK values.\")\n",
    "\n",
    "company_list = (\n",
    "    df_comp[['CIK', 'companyName']]\n",
    "    .drop_duplicates()\n",
    "    .values\n",
    "    .tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96b28819-1bc0-46ef-b597-a229cbe407cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ceo = pd.read_csv(os.path.join(data_directory, 'GpbaAbs_vest_clean.csv'), encoding=\"latin1\",low_memory=False)\n",
    "df_ceo['CIK'] = df_ceo['CIK'].astype(str).str.replace(r\"[^\\d]\", \"\", regex=True).astype(int)\n",
    "df_ceo['participantid'] = df_ceo['participantid'].astype(int)\n",
    "# # print(df_ceo)\n",
    "ceo_list = (\n",
    "    df_ceo[['CIK', 'participantid']]\n",
    "    .drop_duplicates()\n",
    "    .values\n",
    "    .tolist()\n",
    ")\n",
    "# print(ceo_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "df01cf53-3856-4c56-9af5-b21eb34e532d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_combined(company_name=None, CIK=None, participantid=None, dis=False):\n",
    "    \"\"\"\n",
    "    Reads the CSV files, filters on company_name (substring match, case-insensitive),\n",
    "    CIK, and participantid if they are provided. Returns the combined DataFrame with\n",
    "    columns: [CIK, companyName, metric, fiscalYear, grantDate, startDate, endDate, value, absRel].\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Read CSVs ---\n",
    "    df_abs = pd.read_csv(os.path.join(data_directory, 'GpbaAbs_vest.csv'))\n",
    "    df_rel = pd.read_csv(os.path.join(data_directory, 'GpbaRel_vest.csv'))\n",
    "\n",
    "    # --- Filter the DataFrames ---\n",
    "    if company_name:\n",
    "        df_abs_filtered = df_abs[(df_abs['companyName'].str.contains(company_name, case=False, na=False))& (df_abs['participantid'] == float(participantid))]\n",
    "        df_rel_filtered = df_rel[(df_rel['companyName'].str.contains(company_name, case=False, na=False))& (df_rel['participantid'] == float(participantid))]\n",
    "    else:\n",
    "        df_abs_filtered = df_abs[(df_abs['CIK'] == CIK) & (df_abs['participantid'] == float(participantid))]\n",
    "        df_rel_filtered = df_rel[(df_rel['CIK'] == CIK) & (df_rel['participantid'] == float(participantid))]\n",
    "\n",
    "    if df_abs_filtered.empty and df_rel_filtered.empty:\n",
    "        print(f\"No data found for CIK={CIK}, participant={participantid}.\")\n",
    "        return  # nothing else to plot\n",
    "    \n",
    "    # --- Select columns and label abs/rel ---\n",
    "    columns_to_display = [\n",
    "        'CIK', 'companyName', 'metric', 'fiscalYear', \n",
    "        'grantDate', 'startDate', 'endDate', 'size', 'percentVest', 'value', 'grantId'\n",
    "    ]\n",
    "    df_abs_filtered = df_abs_filtered[columns_to_display].copy()\n",
    "    df_rel_filtered = df_rel_filtered[columns_to_display].copy()\n",
    "\n",
    "    df_abs_filtered['absRel'] = 'abs'\n",
    "    df_rel_filtered['absRel'] = 'rel'\n",
    "\n",
    "    df_combined = pd.concat([df_abs_filtered, df_rel_filtered], ignore_index=True)\n",
    "    df_combined = df_combined.sort_values(by=['metric', 'grantDate'], ascending=[True, True])\n",
    "\n",
    "    # Display the combined DataFrame (in notebook)\n",
    "    if dis:\n",
    "        display(df_combined)\n",
    "\n",
    "    return df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22ac530f-886a-411d-9dc8-2ae9c6653c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_compensation_timeline(company_name, CIK, participantid, dis=False):\n",
    "    \"\"\"\n",
    "    Reads the vest CSV files, filters on CIK & participantid,\n",
    "    displays the combined DataFrame, and plots the timeline.\n",
    "    \"\"\"\n",
    "    df_combined = create_df_combined(company_name=company_name, CIK=CIK, participantid=participantid, dis=dis)\n",
    "    if df_combined.empty:\n",
    "        print(f\"No data found for company={company_name}, CIK={CIK}, participant={participantid}.\")\n",
    "        return\n",
    "\n",
    "    # --- Convert date columns to datetime ---\n",
    "    df_combined['grantDate'] = pd.to_datetime(df_combined['grantDate'], errors='coerce')\n",
    "    df_combined['startDate'] = pd.to_datetime(df_combined['startDate'], errors='coerce')\n",
    "    df_combined['endDate']   = pd.to_datetime(df_combined['endDate'], errors='coerce')\n",
    "\n",
    "    # --- Retrieve base salary data ---\n",
    "    if pd.isna(CIK):  # If company_name is used, map it to CIK\n",
    "        CIK = df_combined['CIK'].iloc[0] if not df_combined.empty else None\n",
    "\n",
    "    base_filtered = base[(base['CIK'] == CIK) & (base['participantid'] == participantid)]\n",
    "\n",
    "    # Convert fiscalYear to integer for sorting\n",
    "    base_filtered.loc[:,'FiscalYear'] = pd.to_numeric(base_filtered['FiscalYear'], errors='coerce')\n",
    "\n",
    "    # --- Compute the minimum value for scaling line thickness ---\n",
    "    min_val = pd.concat([df_combined['size'], base_filtered['salary']], axis=0).dropna().min()\n",
    "\n",
    "    # --- Sort metrics by frequency ---\n",
    "    metric_counts = df_combined['metric'].value_counts(ascending=True)\n",
    "    sorted_metrics = metric_counts.index.tolist()\n",
    "\n",
    "    df_combined['metric'] = pd.Categorical(\n",
    "        df_combined['metric'], \n",
    "        categories=sorted_metrics, \n",
    "        ordered=True\n",
    "    )\n",
    "    df_combined = df_combined.sort_values(by=['metric', 'grantDate'])\n",
    "\n",
    "    # --- Set up color map, positions, etc. ---\n",
    "    palette = sns.color_palette(\"colorblind\", 10)\n",
    "    color_map = {'abs': palette[0], 'rel': palette[1]}\n",
    "\n",
    "    metric_positions = {}\n",
    "    y_positions = []\n",
    "    metric_labels = {}\n",
    "\n",
    "    current_y = 2\n",
    "    for metric in sorted_metrics:\n",
    "        metric_rows = df_combined[df_combined['metric'] == metric]\n",
    "        metric_positions[metric] = current_y\n",
    "        row_count = len(metric_rows)\n",
    "        for _ in range(row_count):\n",
    "            y_positions.append(current_y)\n",
    "            current_y += 1\n",
    "        # Center label between these bars\n",
    "        metric_labels[metric] = current_y - (row_count / 2)\n",
    "        current_y += 1  # blank row between metrics\n",
    "\n",
    "    df_combined['y_pos'] = y_positions\n",
    "\n",
    "    # --- Plot ---\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    legend_labels = {\n",
    "        'absolute, performance period': False,\n",
    "        'relative, performance period': False,\n",
    "        'Grant Date': False\n",
    "    }\n",
    "\n",
    "    min_val = df_combined['size'].dropna().min()\n",
    "    for _, row in df_combined.iterrows():\n",
    "        y = row['y_pos']\n",
    "        if row['absRel'] == 'abs':\n",
    "            line_label = 'absolute, performance period'\n",
    "        else:\n",
    "            line_label = 'relative, performance period'\n",
    "\n",
    "        # Decide line style and thickness\n",
    "        if pd.isna(row['size']):\n",
    "            ls = '--'           # dashed line if value is NaN\n",
    "            lw = 1             # pick a default thickness for NaN rows\n",
    "        else:\n",
    "            ls = '-'           # solid line if value is not NaN\n",
    "            # example scaling: if 'value' is large, you can divide or clamp it\n",
    "            # e.g. ensure minimum thickness of 1\n",
    "            lw = 1 * row['size'] / min_val\n",
    "            # adjust divisor or logic to suit your data distribution\n",
    "    \n",
    "        # performance period bar\n",
    "        color = color_map[row['absRel']]\n",
    "        if not legend_labels[line_label]:\n",
    "            ax.plot([row['startDate'], row['endDate']], [y, y], \n",
    "                    color=color, linewidth=lw, linestyle=ls,\n",
    "                    label=line_label)\n",
    "            legend_labels[line_label] = True\n",
    "        else:\n",
    "            ax.plot([row['startDate'], row['endDate']], [y, y],\n",
    "                    color=color, linewidth=lw, linestyle=ls)\n",
    "\n",
    "        # grant date marker\n",
    "        if not legend_labels['Grant Date']:\n",
    "            ax.scatter(row['grantDate'], y, color='black', marker='o', label='Grant Date')\n",
    "            legend_labels['Grant Date'] = True\n",
    "        else:\n",
    "            ax.scatter(row['grantDate'], y, color='black', marker='o')\n",
    "\n",
    "    # --- Plot Base Salary ---\n",
    "    base_salary_y = 0  # Position below the lowest metric\n",
    "    base_salary_legend_added = False\n",
    "    for _, row in base_filtered.iterrows():\n",
    "        fiscal_year = int(row['FiscalYear'])\n",
    "        salary_value = row['salary']\n",
    "        if pd.notna(salary_value):\n",
    "            lw = 1 * salary_value / min_val  # Scale thickness\n",
    "            ax.plot([pd.Timestamp(f\"{fiscal_year}-01-01\"), pd.Timestamp(f\"{fiscal_year}-12-31\")], \n",
    "                    [base_salary_y, base_salary_y], color='black', linewidth=lw, label='Base Salary')\n",
    "            base_salary_legend_added = True \n",
    "            \n",
    "    # horizontal dashed lines to separate metrics\n",
    "    for metric, pos in metric_positions.items():\n",
    "        ax.axhline(y=pos - 1, color='gray', linestyle='dashed', alpha=0.3)\n",
    "\n",
    "    # Label y-axis for base salary\n",
    "    # ax.text(pd.Timestamp(f\"{base_filtered['FiscalYear'].min()}-01-01\"), base_salary_y, \n",
    "            # \"Base Salary\", ha='right', va='center', fontsize=10, color='black')\n",
    "\n",
    "    ax.set_xlabel(\"Time\")\n",
    "\n",
    "    # Title (use the first non-null companyName)\n",
    "    if df_combined['companyName'].dropna().empty:\n",
    "        title = f\"Metric-Level Timeline (CIK={CIK}, participant={participantid})\"\n",
    "    else:\n",
    "        title = f\"Metric-Level Timeline for {df_combined['companyName'].iloc[0]}, CEO {participantid}\"\n",
    "    ax.set_title(title)\n",
    "\n",
    "    # y-ticks\n",
    "    ax.set_yticks(list(metric_labels.values()) + [base_salary_y])\n",
    "    ax.set_yticklabels(list(metric_labels.keys()) + [\"Base Salary\"])\n",
    "\n",
    "    # Format x-axis as Year-Month\n",
    "    ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "    ax.xaxis.set_minor_locator(mdates.MonthLocator())\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # Legend ordering\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    desired_order = ['absolute, performance period', 'relative, performance period', 'Grant Date', 'Base Salary']\n",
    "    ordered_handles = [handles[labels.index(lbl)] for lbl in desired_order if lbl in labels]\n",
    "    plt.legend(ordered_handles, desired_order, loc='upper left')\n",
    "\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Optionally save figure\n",
    "    # This line saves it under timeline/companyName.jpg if you want\n",
    "    # If there's a valid companyName, otherwise fallback:\n",
    "    safe_name = title.replace(\" \", \"_\").replace(\"/\", \"_\")\n",
    "    plot_path = os.path.join(graph_directory, f\"{safe_name}_metric_timeline.jpg\")\n",
    "    plt.savefig(plot_path)\n",
    "\n",
    "    # print(f\"Plot saved to: {plot_path}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64596096-049a-4e5c-b78d-bddebaa30c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_compensation_timeline_by_grant(company_name, CIK, participantid, dis=False):\n",
    "    \"\"\"\n",
    "    Group df_combined by 'grantId'. \n",
    "    For each group, determine distinct (grantDate, startDate, endDate) combos.\n",
    "    Plot one horizontal line per distinct combo. \n",
    "    Label the y-axis with:\n",
    "      - if there's only one distinct timeline, show the list of metrics in the group\n",
    "      - if multiple timelines exist, show separate lines, labeling each line with the relevant metrics\n",
    "    \"\"\"\n",
    "    df_combined = create_df_combined(company_name=company_name, CIK=CIK, participantid=participantid, dis=dis)\n",
    "    if df_combined.empty:\n",
    "        print(f\"No data found for company={company_name}, CIK={CIK}, participant={participantid}.\")\n",
    "        return\n",
    "\n",
    "    # Just in case, ensure these are datetimes\n",
    "    df_combined['grantDate'] = pd.to_datetime(df_combined['grantDate'], errors='coerce')\n",
    "    df_combined['startDate'] = pd.to_datetime(df_combined['startDate'], errors='coerce')\n",
    "    df_combined['endDate']   = pd.to_datetime(df_combined['endDate'], errors='coerce')\n",
    "\n",
    "    # --- Retrieve base salary data ---\n",
    "    if pd.isna(CIK):  # If company_name is used, map it to CIK\n",
    "        CIK = df_combined['CIK'].iloc[0] if not df_combined.empty else None\n",
    "\n",
    "    base_filtered = base[(base['CIK'] == CIK) & (base['participantid'] == participantid)]\n",
    "\n",
    "    # Convert fiscalYear to integer for sorting\n",
    "    base_filtered.loc[:,'FiscalYear'] = pd.to_numeric(base_filtered['FiscalYear'], errors='coerce')\n",
    "    \n",
    "    # --- Compute the minimum value for scaling line thickness ---\n",
    "    min_value = pd.concat([df_combined['size'], base_filtered['salary']], axis=0).dropna().min()\n",
    "\n",
    "    # Group by grantId\n",
    "    grouped = df_combined.groupby('grantId', dropna=False)\n",
    "    group_grant_dates = {grantId: sub_df['grantDate'].min() for grantId, sub_df in grouped}\n",
    "    sorted_groups = sorted(group_grant_dates.items(), key=lambda x: x[1])\n",
    "\n",
    "    # Prepare the figure\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    # For coloring, reuse your color scheme if you want\n",
    "    palette = sns.color_palette(\"colorblind\", 10)\n",
    "    color_map = {'abs': palette[0], 'rel': palette[1]}\n",
    "    \n",
    "    # We'll keep track of the y-position for each group\n",
    "    current_y = 2\n",
    "    y_positions = []\n",
    "    y_labels = []\n",
    "\n",
    "    # Track legend entries\n",
    "    legend_labels = {\n",
    "        'absolute, performance period': False,\n",
    "        'relative, performance period': False,\n",
    "        'Grant Date': False,\n",
    "        'Base Salary': False\n",
    "    }\n",
    "    sorted_grant_ids = sorted(grouped.groups.keys(), key=lambda x: group_grant_dates[x])\n",
    "\n",
    "    for grant_id in sorted_grant_ids:\n",
    "        ax.axhline(y=current_y, color='gray', linestyle='dashed', alpha=0.3)\n",
    "        group_df = grouped.get_group(grant_id)  # Retrieve the actual DataFrame\n",
    "        label_for_group = f\"GrantID={grant_id}\" if pd.notna(grant_id) else \"Unknown GrantId\"\n",
    "\n",
    "        # Identify distinct combos within this group\n",
    "        combo_groups = group_df.groupby(['grantDate', 'startDate', 'endDate'], dropna=False)\n",
    "        \n",
    "        # If only 1 distinct timeline, we label the y-axis with all metrics from the entire group\n",
    "        # else, we label each timeline line with its metrics\n",
    "        if len(combo_groups) == 1:\n",
    "            # There's just one combo => we can directly get that\n",
    "            (gDate, sDate, eDate), sub_df = list(combo_groups)[0]\n",
    "            \n",
    "            # Plot one line\n",
    "            first_value = sub_df['value'].iloc[0] if not sub_df['value'].isna().all() else min_value\n",
    "            total_height = 2 * (first_value / min_value) if min_value else 2\n",
    "            # 1) Check if percentVest has NaNs\n",
    "            if sub_df['percentVest'].isna().any():\n",
    "                use_count_based = True\n",
    "                total_count = len(sub_df)\n",
    "                sub_df['computedVest'] = total_height / total_count  # Equal height for all rows\n",
    "                linestyle = '--'  # Dashed lines since we are using fallback\n",
    "            else:\n",
    "                use_count_based = False\n",
    "                total_percentVest = sub_df['percentVest'].sum()\n",
    "                if total_percentVest == 0 or pd.isna(total_percentVest):\n",
    "                    total_percentVest = 1  # Avoid division by zero\n",
    "                sub_df['computedVest'] = sub_df['percentVest'] / total_percentVest * total_height\n",
    "                linestyle = '-'  # Solid lines for percent-based stacking\n",
    "        \n",
    "            # 2) Sort by 'absRel' (absolute first, then relative), then by height (largest to smallest)\n",
    "            sub_df = sub_df.sort_values(by=['absRel', 'computedVest'], ascending=[False, True])\n",
    "            sorted_metrics = sub_df['metric'].tolist()[::-1]  # Get metric names in the same order as stacks\n",
    "            metric_label = \", \".join(sorted_metrics) if sorted_metrics else \"No Metric\"\n",
    "\n",
    "            # 3) Compute the vertical stacking based on computedVest\n",
    "            start_y = current_y\n",
    "            for _, row in sub_df.iterrows():\n",
    "                height = row['computedVest']\n",
    "                color = color_map.get(row['absRel'], 'gray')\n",
    "\n",
    "                line_label = 'absolute, performance period' if row['absRel'] == 'abs' else 'relative, performance period'\n",
    "\n",
    "                # Draw stacked vertical section\n",
    "                if not legend_labels[line_label]:\n",
    "                    ax.plot([sDate, eDate],\n",
    "                            [start_y + height/2, start_y + height/2],\n",
    "                            color=color, linestyle=linestyle, linewidth=height, label=line_label)\n",
    "                    legend_labels[line_label] = True\n",
    "                else:\n",
    "                    ax.plot([sDate, eDate],\n",
    "                            [start_y + height/2, start_y + height/2],\n",
    "                            color=color, linestyle=linestyle, linewidth=height)\n",
    "        \n",
    "                # Move up to stack the next segment\n",
    "                start_y += height\n",
    "            \n",
    "            # Plot the grant date marker\n",
    "            ax.scatter(gDate, current_y + total_height / 2, color='black', marker='o', label=\"Grant Date\" if not legend_labels['Grant Date'] else \"\", zorder=5)\n",
    "            legend_labels['Grant Date'] = True\n",
    "\n",
    "            # We'll label the entire group's y-tick with the list of metrics\n",
    "            y_positions.append(current_y+ total_height/2)\n",
    "            y_labels.append(f\"{label_for_group}\\n({metric_label})\")\n",
    "\n",
    "            current_y += total_height + 1  # move down for next group\n",
    "\n",
    "        else:\n",
    "            # Multiple distinct combos => each timeline gets its own line\n",
    "            # We'll label each line with the relevant metrics\n",
    "            base_y = current_y\n",
    "            lines_in_group = 0\n",
    "\n",
    "            for (gDate, sDate, eDate), sub_df in combo_groups:\n",
    "                # gather metrics for *this timeline*\n",
    "                first_value = sub_df['value'].iloc[0] if not sub_df['value'].isna().all() else min_value\n",
    "                total_height = 1 * (first_value / min_value) if min_value else 1\n",
    "                # 1) Check if percentVest has NaNs\n",
    "                if sub_df['percentVest'].isna().any():\n",
    "                    use_count_based = True\n",
    "                    total_count = len(sub_df)\n",
    "                    sub_df['computedVest'] = total_height / total_count  # Equal height for all rows\n",
    "                    linestyle = '--'  # Dashed lines since we are using fallback\n",
    "                else:\n",
    "                    use_count_based = False\n",
    "                    total_percentVest = sub_df['percentVest'].sum()\n",
    "                    if total_percentVest == 0 or pd.isna(total_percentVest):\n",
    "                        total_percentVest = 1  # Avoid division by zero\n",
    "                    sub_df['computedVest'] = sub_df['percentVest'] / total_percentVest * total_height\n",
    "                    linestyle = '-'  # Solid lines for percent-based stacking\n",
    "\n",
    "                # 2) Sort by 'absRel' (absolute first, then relative), then by height (largest to smallest)\n",
    "                sub_df = sub_df.sort_values(by=['absRel', 'computedVest'], ascending=[False, True])\n",
    "                sorted_metrics = sub_df['metric'].tolist()[::-1]  # Get metric names in the same order as stacks\n",
    "                metric_label = \", \".join(sorted_metrics) if sorted_metrics else \"No Metric\"\n",
    "            \n",
    "                # 3) Compute the vertical stacking based on computedVest\n",
    "                start_y = current_y\n",
    "                for _, row in sub_df.iterrows():\n",
    "                    height = row['computedVest']\n",
    "                    color = color_map.get(row['absRel'], 'gray')\n",
    "            \n",
    "                    line_label = 'absolute, performance period' if row['absRel'] == 'abs' else 'relative, performance period'\n",
    "\n",
    "                    # Draw stacked vertical section\n",
    "                    if not legend_labels[line_label]:\n",
    "                        ax.plot([sDate, eDate],\n",
    "                            [start_y + height/2, start_y + height/2],\n",
    "                            color=color, linestyle=linestyle, linewidth=height)\n",
    "                        legend_labels[line_label] = True\n",
    "                    else:\n",
    "                        ax.plot([sDate, eDate],\n",
    "                            [start_y + height/2, start_y + height/2],\n",
    "                            color=color, linestyle=linestyle, linewidth=height)\n",
    "                    # Move up to stack the next segment\n",
    "                    start_y += height\n",
    "\n",
    "                # Add a text annotation near the middle of the line with the metrics\n",
    "                mid_x = sDate + (eDate - sDate) / 2 if (pd.notna(sDate) and pd.notna(eDate)) else sDate\n",
    "                ax.text(mid_x, current_y + total_height / 2, metric_label, ha='center', va='bottom', fontsize=9, color='black')\n",
    "\n",
    "                # Plot the grant date marker\n",
    "                ax.scatter(gDate, current_y + total_height / 2, color='black', marker='o', label=\"Grant Date\" if not legend_labels['Grant Date'] else \"\", zorder=5)\n",
    "                legend_labels['Grant Date'] = True\n",
    "\n",
    "                current_y += total_height + 1\n",
    "                lines_in_group += 1\n",
    "\n",
    "            # after multiple lines, we can label the base_y with the group name\n",
    "            # e.g. put a label at the midpoint of those lines\n",
    "            group_center_y = base_y + (lines_in_group - 1) / 2\n",
    "            y_positions.append(group_center_y)\n",
    "            y_labels.append(label_for_group)\n",
    "            current_y += 1  # blank space between groups\n",
    "\n",
    "    # --- Plot Base Salary ---\n",
    "    base_salary_y = 0  # Position below the lowest metric\n",
    "    for _, row in base_filtered.iterrows():\n",
    "        fiscal_year = int(row['FiscalYear'])\n",
    "        salary_value = row['salary']\n",
    "        if pd.notna(salary_value):\n",
    "            lw = 2 * salary_value / min_value  # Scale thickness\n",
    "            ax.plot([pd.Timestamp(f\"{fiscal_year}-01-01\"), pd.Timestamp(f\"{fiscal_year}-12-31\")], \n",
    "                    [base_salary_y, base_salary_y], color='black', linewidth=lw, label='Base Salary')\n",
    "            legend_labels['Base Salary'] = True\n",
    "\n",
    "    # Decorate axes\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    ax.set_ylabel(\"Grant-level grouping\")\n",
    "\n",
    "    # Format x-axis as Year-Month\n",
    "    ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "    ax.xaxis.set_minor_locator(mdates.MonthLocator())\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # ax.set_yticks(y_positions)\n",
    "    # ax.set_yticklabels(y_labels)\n",
    "    # y-ticks\n",
    "    ax.set_yticks(y_positions + [base_salary_y])\n",
    "    ax.set_yticklabels(y_labels + [\"Base Salary\"])\n",
    "\n",
    "    ax.grid(axis='x', linestyle='--', alpha=0.6)\n",
    "\n",
    "    # --- Ensure Proper Legend ---\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    desired_order = ['absolute, performance period', 'relative, performance period', 'Grant Date', 'Base Salary']\n",
    "    final_labels = [lbl for lbl in desired_order if legend_labels.get(lbl, False)]\n",
    "    ordered_handles = [handles[labels.index(lbl)] for lbl in final_labels if lbl in labels]\n",
    "    ax.legend(ordered_handles, final_labels, loc='upper left')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.title(f\"Grant-Level Timeline for {df_combined['companyName'].iloc[0]}, CEO {participantid}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfbf066e-448e-417b-bc5c-d396f42aaae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f4c926873704cf39b22f8f7aaca22fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Text(value='Kellogg', description='Company:'), IntText(value=55067, description=…"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ######### Create input widgets\n",
    "# company_widget = widgets.Text(value=\"Kellogg\", description=\"Company:\")\n",
    "# CIK_widget = widgets.IntText(value=55067, description=\"CIK:\")\n",
    "# participant_widget = widgets.IntText(value=58579, description=\"CEO ID:\")\n",
    "# run_button = widgets.Button(description=\"Generate Timeline\")\n",
    "\n",
    "# # This output area will display the DataFrame and the plot\n",
    "# output_area = widgets.Output()\n",
    "\n",
    "# def on_run_button_click(b):\n",
    "#     \"\"\"\n",
    "#     Clears the output area, then runs the plotting function.\n",
    "#     \"\"\"\n",
    "#     with output_area:\n",
    "#         output_area.clear_output()\n",
    "#         company_val = company_widget.value\n",
    "#         CIK_val = CIK_widget.value\n",
    "#         participant_val = participant_widget.value\n",
    "#         # plot_compensation_timeline(company_val, CIK_val, participant_val, False)\n",
    "#         plot_compensation_timeline_by_grant(company_val, CIK_val, participant_val, False)\n",
    "        \n",
    "# run_button.on_click(on_run_button_click)\n",
    "\n",
    "# # Display the widgets & output in the notebook\n",
    "# widgets.VBox([\n",
    "#     widgets.HBox([company_widget, CIK_widget, participant_widget]),\n",
    "#     run_button,\n",
    "#     output_area\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "39161142-fe96-4f70-b8c9-87967ba0f262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da504ee24dda4df887922ba161367499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Combobox(value='', description='Company:', options=('21st Century Insurance Grou…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build sets of all names, all CIKs:\n",
    "all_company_names = sorted({nm for (_, nm) in company_list})\n",
    "all_ciks = sorted({c for (c, _) in company_list})\n",
    "all_ceos = sorted({p for (_, p) in ceo_list})\n",
    "\n",
    "def filter_company_names(substring):\n",
    "    \"\"\"Return a list of company names containing 'substring' (case-insensitive).\"\"\"\n",
    "    s_lower = substring.lower()\n",
    "    return [n for n in all_company_names if s_lower in n.lower()]\n",
    "\n",
    "def filter_ciks(substring):\n",
    "    \"\"\"Return a list of CIKs (as strings) containing 'substring'.\"\"\"\n",
    "    return [str(c) for c in all_ciks if substring in str(c)]\n",
    "\n",
    "def filter_ceos(substring):\n",
    "    \"\"\"Return a list of CEOs (as strings) containing 'substring'.\"\"\"\n",
    "    return [str(p) for p in all_ceos if substring in str(p)]\n",
    "\n",
    "def ciks_for_company(company_name):\n",
    "    \"\"\"All CIKs that match the given company_name in company_list, as strings.\"\"\"\n",
    "    return sorted({str(c) for (c, n) in company_list if n == company_name})\n",
    "\n",
    "def names_for_cik(cik_str):\n",
    "    \"\"\"All company names that match the given CIK in company_list.\"\"\"\n",
    "    try:\n",
    "        cik_int = int(cik_str)\n",
    "        return sorted({n for (c, n) in company_list if c == cik_int})\n",
    "    except ValueError:\n",
    "        return []\n",
    "\n",
    "def ceos_for_cik(cik_str):\n",
    "    \"\"\"All CEO names that match the given CIK in ceo_list.\"\"\"\n",
    "    try:\n",
    "        cik_int = int(cik_str)\n",
    "        return sorted({str(item[1]) for item in ceo_list if int(item[0]) == cik_int})\n",
    "    except ValueError:\n",
    "        return []\n",
    "\n",
    "\n",
    "# --- Create dynamic Comboboxes for Company & CIK ---\n",
    "company_widget = widgets.Combobox(\n",
    "    placeholder='Type a company name...',\n",
    "    options=all_company_names,\n",
    "    description='Company:'\n",
    ")\n",
    "# company_widget.value = \"Kellogg\"  # your existing default\n",
    "\n",
    "CIK_widget = widgets.Combobox(\n",
    "    placeholder='Type a CIK...',\n",
    "    options=[str(c) for c in all_ciks],\n",
    "    description='CIK:'\n",
    ")\n",
    "# CIK_widget.value = \"55067\"  # your existing default\n",
    "\n",
    "participant_widget = widgets.Combobox(\n",
    "    placeholder='Type a CEO ID...',\n",
    "    options=[str(p) for p in all_ceos],\n",
    "    description='CEO ID:'\n",
    ")\n",
    "# participant_widget.value = \"58579\"  # your existing default\n",
    "\n",
    "run_button = widgets.Button(description=\"Generate Timeline\")\n",
    "output_area = widgets.Output()\n",
    "\n",
    "# Observers for dynamic suggestions:\n",
    "def on_company_typed(change):\n",
    "    if change['name'] == 'value':\n",
    "        typed = change['new'].strip()  # Remove extra whitespace\n",
    "        typed = change['new']\n",
    "        # Filter company suggestions\n",
    "        company_widget.options = [\n",
    "            n for n in all_company_names \n",
    "            if typed.lower() in n.lower()\n",
    "        ]\n",
    "        \n",
    "        # If typed is an exact known name => narrow CIK options\n",
    "        if typed in all_company_names:\n",
    "            # Show only the matched CIK(s)\n",
    "            matched_ciks = ciks_for_company(typed)\n",
    "            CIK_widget.options = matched_ciks\n",
    "\n",
    "            # If the current typed CIK isn't in matched_ciks, clear the CIK\n",
    "            if CIK_widget.value not in matched_ciks:\n",
    "                CIK_widget.value = \"\"  # Clear if mismatch\n",
    "        else:\n",
    "            # Not a finalized name => you could restore full CIK list or partial filter\n",
    "            CIK_widget.options = []\n",
    "            CIK_widget.value = \"\"\n",
    "            pass\n",
    "\n",
    "def on_cik_typed(change):\n",
    "    if change['name'] == 'value':\n",
    "        typed = change['new'].strip()\n",
    "        print(\"CIK typed:\", typed)  # Debug print\n",
    "        # Filter suggestions for CIK\n",
    "        CIK_widget.options = filter_ciks(typed)\n",
    "        known_ciks = [str(c) for c in all_ciks]\n",
    "        # print(\"Known CIKs:\", known_ciks)  # Debug print\n",
    "        \n",
    "        # If typed is exactly one known CIK:\n",
    "        if typed in known_ciks:\n",
    "            # Show only the matched company name(s)\n",
    "            matched_names = names_for_cik(typed)\n",
    "            company_widget.options = matched_names\n",
    "            \n",
    "            matched_ceos = ceos_for_cik(typed)\n",
    "            print(\"Matched CEOs for CIK\", typed, \":\", matched_ceos)  # Debug print\n",
    "            participant_widget.options = matched_ceos\n",
    "\n",
    "            # If the current typed company isn't in matched_names, clear the company\n",
    "            if company_widget.value not in matched_names:\n",
    "                company_widget.value = \"\"\n",
    "            if participant_widget.value not in matched_ceos:\n",
    "                participant_widget.value = \"\"\n",
    "        else:\n",
    "            # Not a finalized CIK => you could restore full name list or partial filter\n",
    "            company_widget.options = []\n",
    "            company_widget.value = \"\"\n",
    "            participant_widget.options = filter_ceos(typed)\n",
    "            participant_widget.value = \"\"\n",
    "\n",
    "company_widget.observe(on_company_typed, names='value')\n",
    "CIK_widget.observe(on_cik_typed, names='value')\n",
    "\n",
    "\n",
    "def on_run_button_click(b):\n",
    "    \"\"\"\n",
    "    Clears the output area, then runs the plotting function.\n",
    "    \"\"\"\n",
    "    with output_area:\n",
    "        output_area.clear_output()\n",
    "        \n",
    "        company_val = company_widget.value\n",
    "        cik_val_str = CIK_widget.value\n",
    "        try:\n",
    "            CIK_val = int(cik_val_str)  # convert typed string to int\n",
    "        except ValueError:\n",
    "            CIK_val = None  # or handle error\n",
    "        participant_val = participant_widget.value\n",
    "\n",
    "        # Now call your timeline function(s)\n",
    "        plot_compensation_timeline(company_val, CIK_val, participant_val, False)\n",
    "        plot_compensation_timeline_by_grant(company_val, CIK_val, participant_val, False)\n",
    "\n",
    "run_button.on_click(on_run_button_click)\n",
    "\n",
    "# Display the widgets & output in the notebook\n",
    "display(\n",
    "    widgets.VBox([\n",
    "        widgets.HBox([company_widget, CIK_widget, participant_widget]),\n",
    "        run_button,\n",
    "        output_area\n",
    "    ])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a360a4b-5a8b-4bb4-be2c-80577c4b73de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
