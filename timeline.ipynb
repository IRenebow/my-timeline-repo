{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1bf58a27-b4cb-4c8b-87f7-879e237fb2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### loading the packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.patches as patches\n",
    "import ipywidgets as widgets\n",
    "import voila\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35249c1e-13e9-4d12-a981-9cd818c92f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of a global directory, just use relative folders:\n",
    "# os.chdir(\"/Users/ruofeiguo/CEO Compensation/my-timeline-repo\")\n",
    "data_directory = \"data\"\n",
    "# graph_directory = \"graph\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b543138-796e-4954-b0b5-428bd7a06242",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = pd.read_csv(os.path.join(data_directory, 'SumComp.csv'))\n",
    "base['CIK'] = base['CIK'].astype(str).str.replace(r\"[^\\d]\", \"\", regex=True).astype(int)\n",
    "# # base.to_csv(os.path.join(data_directory, 'SumComp.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9cb88355-b165-4e64-b019-eda84641bd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "grant = pd.read_csv(os.path.join(data_directory, 'GpbaGrant_clean.csv'))\n",
    "# grant_award = pd.read_csv(os.path.join(data_directory, 'GpbaGrant_CEO.csv'))\n",
    "# # print(grant_award.head)\n",
    "# grant = grant.merge(grant_award[['grantID', 'AwardType']], on='grantID', how='left')\n",
    "# # print(grant.head)\n",
    "# grant.to_csv(os.path.join(data_directory, 'GpbaGrant_clean.csv'), index=False)\n",
    "# print(grant.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f8b3be2-b434-4475-b659-d1649b29137d",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = pd.read_csv(os.path.join(data_directory, 'GpbaTime_vest.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a4f6cec4-1573-4a50-a883-0e1232a60d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_abs = pd.read_csv(os.path.join(data_directory, 'GpbaAbs_vest_clean.csv'), encoding=\"latin1\")\n",
    "df_rel = pd.read_csv(os.path.join(data_directory, 'GpbaRel_vest.csv'))\n",
    "columns_to_display = [\n",
    "        'CIK', 'participantid', 'companyName', 'metric', 'fiscalYear', \n",
    "        'grantDate', 'startDate', 'endDate', 'size', 'percentVest', 'value', 'grantId', 'group'\n",
    "    ]\n",
    "df_abs_filtered = df_abs[columns_to_display]\n",
    "df_rel_filtered = df_rel[columns_to_display]\n",
    "df_comp = pd.concat([df_abs_filtered, df_rel_filtered], ignore_index=True)\n",
    "\n",
    "df_comp['participantid'] = df_comp['participantid'].astype(int)\n",
    "\n",
    "# unique_list = (\n",
    "#     df_comp[['CIK', 'companyName', 'participantid']]\n",
    "#     .drop_duplicates()\n",
    "#     .values\n",
    "#     .tolist()\n",
    "# )\n",
    "\n",
    "unique_cik = (\n",
    "    df_comp[['CIK', 'companyName']]\n",
    "    .drop_duplicates()\n",
    "    .values\n",
    "    .tolist()\n",
    ")\n",
    "cik_to_company = {cik: name for cik, name in unique_cik}\n",
    "company_to_cik = {name: cik for cik, name in unique_cik}\n",
    "\n",
    "unique_ceo = (\n",
    "    df_comp[['companyName', 'participantid', 'fiscalYear']]\n",
    "    .drop_duplicates()\n",
    ")\n",
    "unique_ceo = unique_ceo.loc[unique_ceo.groupby(['companyName', 'participantid'])['fiscalYear'].idxmin()]\n",
    "company_to_ceo = (\n",
    "    unique_ceo.sort_values(by=['companyName', 'fiscalYear'])\n",
    "    .groupby('companyName')['participantid']\n",
    "    .apply(list)\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# Function to get participantid list for a given company\n",
    "def get_participants_for_company(company_val):\n",
    "    return company_to_ceo.get(company_val, [])  # Returns empty list if not found\n",
    "\n",
    "all_company_names = (\n",
    "    df_comp['companyName']\n",
    "    .drop_duplicates()\n",
    "    .values\n",
    "    .tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ced15afe-3e74-4d0b-a455-49277a836304",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part = pd.read_csv(os.path.join(data_directory, 'ParticipantFY.csv'), encoding=\"latin1\", low_memory=False)\n",
    "participant_dict = df_part.drop_duplicates(subset=['participantid', 'fullName']).set_index('participantid')['fullName'].to_dict()\n",
    "\n",
    "# df_part = df_part[['participantid', 'fullName', 'FiscalYear']]\n",
    "# print(df_part.head)\n",
    "# df_part = df_part.dropna(subset=['participantid'])\n",
    "# df_part = df_part.dropna(subset=['FiscalYear'])\n",
    "# df_part.to_csv(os.path.join(data_directory, 'ParticipantFY.csv'), index=False)\n",
    "\n",
    "# def resolve_ceoname_id_conflicts(df_comp):\n",
    "#     # Step 1: Resolve multiple companyNames for the same CIK\n",
    "#     df_comp_sorted = df_comp.sort_values(by=['participantid', 'FiscalYear', 'fullName'], ascending=[True, False, False])\n",
    "\n",
    "#     # Select the best companyName for each CIK (latest fiscalYear, longest name)\n",
    "#     best_company_mapping = df_comp_sorted.drop_duplicates(subset=['participantid'], keep='first').set_index('participantid')['fullName']\n",
    "\n",
    "#     # Map the best companyName to all rows with that CIK\n",
    "#     df_comp['fullName'] = df_comp['participantid'].map(best_company_mapping)\n",
    "\n",
    "#     # Step 2: Resolve multiple CIKs for the same companyName\n",
    "#     cik_counts = df_comp.groupby('fullName')['participantid'].transform('nunique')  # Unique CIKs per company\n",
    "#     multiple_cik_mask = cik_counts > 1  # Identify companies linked to multiple CIKs\n",
    "\n",
    "#     # Assign ranks to CIKs within the same company\n",
    "#     df_comp['cik_rank'] = df_comp.groupby('fullName')['participantid'].rank(method='dense', ascending=True).astype(\"Int64\")\n",
    "\n",
    "#     # Rename only when needed\n",
    "#     df_comp.loc[multiple_cik_mask, 'fullName'] = df_comp['fullName'] + \"(\" + df_comp['cik_rank'].astype(str) + \")\"\n",
    "\n",
    "#     # Drop the helper column\n",
    "#     df_comp.drop(columns=['cik_rank'], inplace=True)\n",
    "\n",
    "#     # Step 3: Verify One-to-One Mapping\n",
    "#     cik_to_name_counts = df_comp.groupby('participantid')['fullName'].nunique()\n",
    "#     name_to_cik_counts = df_comp.groupby('fullName')['participantid'].nunique()\n",
    "\n",
    "#     assert cik_to_name_counts.max() == 1, \"Some IDs still map to multiple CEOs!\"\n",
    "#     assert name_to_cik_counts.max() == 1, \"Some CEOs still map to multiple IDs!\"\n",
    "    \n",
    "#     # Ensure the shape remains the same\n",
    "#     assert df_comp.shape[0] == original_shape, \"Row count changed! No rows should be dropped.\"\n",
    "\n",
    "#     return df_comp\n",
    "\n",
    "# Apply the function\n",
    "# original_shape = df_part.shape[0]\n",
    "# df_final = resolve_ceoname_id_conflicts(df_part)\n",
    "\n",
    "# # Display the final DataFrame\n",
    "# print(df_final.head)\n",
    "# df_final.to_csv(os.path.join(data_directory, 'ParticipantFY.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "669da12f-45ff-44af-9da6-1f09a35c2ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_rel = pd.read_csv(os.path.join(data_directory, 'GpbaRel_vest.csv'))\n",
    "# df_rel['companyName'] = df_rel['CIK'].map(cik_to_company)\n",
    "# df_rel.to_csv(os.path.join(data_directory, 'GpbaRel_vest.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df01cf53-3856-4c56-9af5-b21eb34e532d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_combined(company_name=None, participantid=None, dis=False):\n",
    "    \"\"\"\n",
    "    Reads the CSV files, filters on company_name (substring match, case-insensitive),\n",
    "    CIK, and participantid if they are provided. Returns the combined DataFrame with\n",
    "    columns: [CIK, companyName, metric, fiscalYear, grantDate, startDate, endDate, value, absRel].\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Read CSVs ---\n",
    "    df_abs = pd.read_csv(os.path.join(data_directory, 'GpbaAbs_vest_clean.csv'))\n",
    "    df_rel = pd.read_csv(os.path.join(data_directory, 'GpbaRel_vest.csv'))\n",
    "\n",
    "    #### get CIK from unique list\n",
    "    CIK = company_to_cik[company_name]\n",
    "\n",
    "    # --- Filter the DataFrames ---\n",
    "    df_abs_filtered = df_abs[(df_abs['CIK'] == CIK) & (df_abs['participantid'] == float(participantid))]\n",
    "    df_rel_filtered = df_rel[(df_rel['CIK'] == CIK) & (df_rel['participantid'] == float(participantid))]\n",
    "\n",
    "    if df_abs_filtered.empty and df_rel_filtered.empty:\n",
    "        print(f\"No data found for CIK={CIK}, participant={participantid}.\")\n",
    "        return  # nothing else to plot\n",
    "    \n",
    "    # --- Select columns and label abs/rel ---\n",
    "    columns_to_display = [\n",
    "        'CIK', 'companyName', 'metric', 'fiscalYear', \n",
    "        'grantDate', 'startDate', 'endDate', 'size', 'percentVest', 'value', 'grantId', 'group'\n",
    "    ]\n",
    "    df_abs_filtered = df_abs_filtered[columns_to_display].copy()\n",
    "    df_rel_filtered = df_rel_filtered[columns_to_display].copy()\n",
    "\n",
    "    df_abs_filtered['absRel'] = 'abs'\n",
    "    df_rel_filtered['absRel'] = 'rel'\n",
    "\n",
    "    df_combined = pd.concat([df_abs_filtered, df_rel_filtered], ignore_index=True)\n",
    "    df_combined = df_combined.sort_values(by=['metric', 'grantDate'], ascending=[True, True])\n",
    "\n",
    "    mask = (\n",
    "        df_combined['percentVest'].isna() &\n",
    "        df_combined['size'].isna() &\n",
    "        (df_combined['metric'] == 'Unknown') &\n",
    "        (df_combined['startDate'] == df_combined['grantDate']) &\n",
    "        (df_combined['grantDate'] == df_combined['endDate'])\n",
    "    )\n",
    "    df_combined = df_combined[~mask]\n",
    "\n",
    "\n",
    "    # Display the combined DataFrame (in notebook)\n",
    "    if dis:\n",
    "        pd.set_option('display.max_rows', None)\n",
    "        pd.set_option('display.max_columns', None)\n",
    "        display(df_combined)\n",
    "\n",
    "    return df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "18bfc52c-98a7-4786-87ed-87a28faacce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_intro_widget(content, is_button=False, grant_id=None):\n",
    "    \"\"\"\n",
    "    Returns a widget (Button or Label) instead of updating VBox immediately.\n",
    "    \"\"\"\n",
    "    if is_button and grant_id is not None:\n",
    "        button = widgets.Button(\n",
    "            description=content,\n",
    "            layout=widgets.Layout(width=\"auto\"),  # Auto width\n",
    "            tooltip=f\"Click to view details for Grant {grant_id}\"\n",
    "        )\n",
    "        def on_button_click(b):\n",
    "            with output_area:\n",
    "                clear_output(wait=True)\n",
    "                print(f\"Grant {grant_id} details:\")\n",
    "        button.on_click(on_button_click)\n",
    "        return button  # Return the button instead of appending\n",
    "\n",
    "    else:\n",
    "        return widgets.Label(value=content)  # Return a plain label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "64596096-049a-4e5c-b78d-bddebaa30c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_compensation_timeline_by_grant(company_name, participantid, dis=False):\n",
    "    award_color_map = {\n",
    "        'Option': 'dimgray', 'reloadOption': 'dimgray', 'phantomOption': 'dimgray',  # Dark grey\n",
    "        'stock': 'lightgray', 'rsu': 'lightgray', 'sarEquity': 'lightgray', \n",
    "        'sarCash': 'lightgray', 'phantomStock': 'lightgray', 'Performance Unit': 'lightgray',  # Light grey\n",
    "    }\n",
    "    award_label_map = {\n",
    "        'Option': 'Option Award', 'reloadOption': 'Option Award', 'phantomOption': 'Option Award',  # Dark grey\n",
    "        'stock': 'Stock Award', 'rsu': 'Stock Award', 'sarEquity': 'Stock Award', \n",
    "        'sarCash': 'Stock Award', 'phantomStock': 'Stock Award', 'Performance Unit': 'Stock Award',  # Light grey\n",
    "    }\n",
    "    global grant_intro_box\n",
    "    intro_widgets = []\n",
    "    grant_text = widgets.HTML(\n",
    "        f\"<b>Information on metrics and their groupings:</b>\"\n",
    "    )    \n",
    "    intro_widgets.append(grant_text)\n",
    "\n",
    "    df_combined = create_df_combined(company_name=company_name, participantid=participantid, dis=dis)\n",
    "    if df_combined.empty:\n",
    "        print(f\"No data found for company={company_name}, CIK={CIK}, participant={participantid}.\")\n",
    "        return\n",
    "\n",
    "    # Just in case, ensure these are datetimes\n",
    "    df_combined['grantDate'] = pd.to_datetime(df_combined['grantDate'], errors='coerce')\n",
    "    df_combined['startDate'] = pd.to_datetime(df_combined['startDate'], errors='coerce')\n",
    "    df_combined['endDate']   = pd.to_datetime(df_combined['endDate'], errors='coerce')\n",
    "\n",
    "    CIK = company_to_cik[company_name]\n",
    "    \n",
    "    # --- Retrieve base salary data ---\n",
    "    if pd.isna(CIK):  # If company_name is used, map it to CIK\n",
    "        CIK = df_combined['CIK'].iloc[0] if not df_combined.empty else None\n",
    "\n",
    "    base_filtered = base[(base['CIK'] == CIK) & (base['participantid'] == int(participantid))]\n",
    "    time_filtered = time[(time['CIK'] == CIK) & (time['participantid'] == int(participantid))]\n",
    "\n",
    "    # Convert fiscalYear to integer for sorting\n",
    "    base_filtered.loc[:,'FiscalYear'] = pd.to_numeric(base_filtered['FiscalYear'], errors='coerce')\n",
    "    \n",
    "    # --- Compute the minimum value for scaling line thickness ---\n",
    "    max_value = pd.concat([df_combined['size'], base_filtered['salary'], base_filtered['stockAwards'], base_filtered['optionAwards'], time_filtered['grantDateFV']], axis=0).dropna().max()\n",
    "\n",
    "    # Group by grantId\n",
    "    grouped = df_combined.groupby('grantId', dropna=False)\n",
    "    group_grant_dates = {grantId: sub_df['grantDate'].min() for grantId, sub_df in grouped}\n",
    "    sorted_groups = sorted(group_grant_dates.items(), key=lambda x: x[1])\n",
    "\n",
    "    # Prepare the figure\n",
    "    fig_width = 12  # Keep a fixed width\n",
    "    fig_height = max(8, (len(grouped)+1) * 0.5)  # Scale height based on number of items\n",
    "    fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "\n",
    "    # For coloring, reuse your color scheme if you want\n",
    "    # palette = sns.color_palette(\"colorblind\", 10)\n",
    "    color_map = {'abs': '#4C72B0', 'rel': '#F4A261'}\n",
    "    \n",
    "    # We'll keep track of the y-position for each group\n",
    "    current_y = 10\n",
    "    y_positions = []\n",
    "    y_labels = []\n",
    "\n",
    "    # Track legend entries\n",
    "    legend_labels = {\n",
    "        'absolute, performance period': False,\n",
    "        'relative, performance period': False,\n",
    "        'Grant Date': False,\n",
    "        'Non-performance-based': False,\n",
    "        'Time-based': False,\n",
    "        'Stock Award': False,\n",
    "        'Cash Award': False,\n",
    "        'Option Award': False\n",
    "    }\n",
    "\n",
    "    # --- Plot Base Salary ---\n",
    "    max_salary_award = 0 if base_filtered['salary'].dropna().empty else max(20 * base_filtered['salary'].dropna().max() / max_value, 0.3)\n",
    "    max_stock_award = 0 if base_filtered['stockAwards'].dropna().empty else max(20 * base_filtered['stockAwards'].dropna().max() / max_value, 0.3)\n",
    "    max_option_award = 0 if base_filtered['optionAwards'].dropna().empty else max(20 * base_filtered['optionAwards'].dropna().max() / max_value, 0.3)\n",
    "    base_salary_y = current_y\n",
    "    stock_y = base_salary_y + max_salary_award/2 + 4 + max_stock_award/2\n",
    "    option_y = stock_y + max_stock_award/2 + 4 + max_option_award/2\n",
    "    ax.axhline(y=base_salary_y + max_salary_award/2 + 2, color='gray', linestyle='dashed', alpha=0.3)\n",
    "    ax.axhline(y=stock_y + max_stock_award/2 + 2, color='gray', linestyle='dashed', alpha=0.3)\n",
    "    for _, row in base_filtered.iterrows():\n",
    "        fiscal_year = int(row['FiscalYear'])\n",
    "        salary_value = row['salary']\n",
    "        salary_height = 0\n",
    "        if pd.notna(salary_value):\n",
    "            height = max(20 * salary_value / max_value, 1)\n",
    "            # Create a rectangle for base salary\n",
    "            base_salary_rect = patches.Rectangle(\n",
    "                (pd.Timestamp(f\"{fiscal_year}-01-01\"), base_salary_y - height / 2),  # (x, y) position\n",
    "                pd.Timedelta(days=365),  # Width covering the full year\n",
    "                height,  # Height scaled to salary value\n",
    "                facecolor='black',\n",
    "                edgecolor='black', \n",
    "                label='Non-performance-based'\n",
    "            )\n",
    "            \n",
    "            ax.add_patch(base_salary_rect)  # Add rectangle to the plot\n",
    "\n",
    "            legend_labels['Non-performance-based'] = True\n",
    "\n",
    "        stock_value = row['stockAwards']\n",
    "        if pd.notna(stock_value):\n",
    "            height = max(20 * stock_value / max_value, 1)\n",
    "            # Create a rectangle for base salary\n",
    "            stock_rect = patches.Rectangle(\n",
    "                (pd.Timestamp(f\"{fiscal_year}-01-01\"), stock_y - height / 2),  # (x, y) position\n",
    "                pd.Timedelta(days=365),  # Width covering the full year\n",
    "                height,  # Height scaled to salary value\n",
    "                facecolor='black',\n",
    "                edgecolor='black', \n",
    "                label='Non-performance-based'\n",
    "            )\n",
    "            \n",
    "            ax.add_patch(stock_rect)  # Add rectangle to the plot\n",
    "            legend_labels['Non-performance-based'] = True\n",
    "\n",
    "        option_value = row['optionAwards']\n",
    "        if pd.notna(option_value):\n",
    "            height = max(20 * option_value / max_value, 1)\n",
    "            # Create a rectangle for base salary\n",
    "            option_rect = patches.Rectangle(\n",
    "                (pd.Timestamp(f\"{fiscal_year}-01-01\"), option_y - height / 2),  # (x, y) position\n",
    "                pd.Timedelta(days=365),  # Width covering the full year\n",
    "                height,  # Height scaled to salary value\n",
    "                facecolor='black',\n",
    "                edgecolor='black', \n",
    "                label='Non-performance-based'\n",
    "            )\n",
    "            \n",
    "            ax.add_patch(option_rect)  # Add rectangle to the plot\n",
    "            legend_labels['Non-performance-based'] = True\n",
    "\n",
    "    current_y = option_y + max_option_award/2 + 2\n",
    "    # --- Plot Time-Based ---\n",
    "    ax.axhline(y=current_y, color='gray', linestyle='dashed', alpha=0.3)\n",
    "    # print(time_filtered)\n",
    "    time_filtered = time_filtered.sort_values(by='grantDate')\n",
    "    time_y = current_y\n",
    "    current_y += 2\n",
    "    all_nan = time_filtered['grantDateFV'].isna().all()\n",
    "    \n",
    "    for _, row in time_filtered.iterrows():\n",
    "        grantDateFV = row['grantDateFV']\n",
    "        sDate = pd.to_datetime(row['startDate'])\n",
    "        eDate = pd.to_datetime(row['endDate'])\n",
    "        gDate = pd.to_datetime(row['grantDate'])\n",
    "        oops = False\n",
    "        if sDate == eDate:\n",
    "            eDate += pd.Timedelta(days=10)\n",
    "            oops = True\n",
    "        \n",
    "        if pd.notna(grantDateFV):\n",
    "            height = max(20 * grantDateFV / max_value, 1)\n",
    "            # Create a rectangle for base salary\n",
    "            rect = patches.Rectangle(\n",
    "                (sDate, current_y),  # (x, y) position\n",
    "                eDate - sDate,  # width\n",
    "                height,  # height in data units\n",
    "                color='#E9C46A',\n",
    "                label='Time-based'\n",
    "            )\n",
    "            \n",
    "            ax.add_patch(rect)  # Add rectangle to the plot\n",
    "            if oops == True:\n",
    "                ax.scatter(gDate, current_y+height/2, color='black', marker='o', s=6, label=\"Grant Date\" if not legend_labels['Grant Date'] else \"\", zorder=0)\n",
    "            else:\n",
    "                ax.scatter(gDate, current_y+height/2, color='black', marker='o', s=6, label=\"Grant Date\" if not legend_labels['Grant Date'] else \"\", zorder=5)\n",
    "            legend_labels['Time-based'] = True\n",
    "            legend_labels['Grant Date'] = True\n",
    "\n",
    "            current_y += height+2\n",
    "        else:\n",
    "            ax.hlines(\n",
    "                y=current_y,\n",
    "                xmin=sDate,\n",
    "                xmax=eDate,\n",
    "                color=\"#E9C46A\",\n",
    "                linestyle=\"dashed\",\n",
    "                linewidth=1.5,  # Adjust thickness of dashed line\n",
    "                label='Time-based' if all_nan else \"\"\n",
    "            )\n",
    "            if oops == True:\n",
    "                ax.scatter(gDate, current_y, color='black', marker='o', s=6, label=\"Grant Date\" if not legend_labels['Grant Date'] else \"\", zorder=0)\n",
    "            else:\n",
    "                ax.scatter(gDate, current_y, color='black', marker='o', s=6, label=\"Grant Date\" if not legend_labels['Grant Date'] else \"\", zorder=5)\n",
    "            legend_labels['Time-based'] = True\n",
    "            legend_labels['Grant Date'] = True\n",
    "            current_y += 2\n",
    "\n",
    "    current_y += 2\n",
    "    time_y = (current_y + time_y)/2\n",
    "        \n",
    "\n",
    "    # --- Plot Performance-Based ---\n",
    "    sorted_grant_ids = sorted(grouped.groups.keys(), key=lambda x: group_grant_dates[x])\n",
    "\n",
    "    for grant_id in sorted_grant_ids:\n",
    "        low = current_y\n",
    "        performance_grouping = grant.loc[grant['grantID'] == grant_id, 'performanceGrouping']\n",
    "    \n",
    "        # If grant_id is found, get the first matching value\n",
    "        performance_grouping = performance_grouping.iloc[0] if not performance_grouping.empty else None\n",
    "        \n",
    "        ax.axhline(y=current_y, color='gray', linestyle='dashed', alpha=0.3)\n",
    "        # old_y = current_y\n",
    "        group_df = grouped.get_group(grant_id)  # Retrieve the actual DataFrame\n",
    "        label_for_group = (f\"grant {grant_id}\" if pd.notna(grant_id) else \"unknown grant\") \n",
    "        group_df = group_df.copy()\n",
    "        group_df['metric_absrel'] = group_df['metric']+group_df['absRel']\n",
    "\n",
    "        novalue = False\n",
    "        if group_df['value'].isna().all():\n",
    "            novalue = True\n",
    "        else:\n",
    "            first_value = group_df['value'].iloc[0] if not group_df['value'].isna().all() else min_value\n",
    "            total_height = max(20 * (first_value / max_value) if max_value else 20,1)\n",
    "            # 1) Check if percentVest has NaNs\n",
    "            if group_df['percentVest'].isna().any():\n",
    "                use_count_based = True\n",
    "                total_count = len(group_df)\n",
    "                group_df['computedVest'] = total_height / total_count  # Equal height for all rows\n",
    "            else:\n",
    "                use_count_based = False\n",
    "                total_percentVest = group_df['percentVest'].sum()\n",
    "                if total_percentVest == 0 or pd.isna(total_percentVest):\n",
    "                    total_percentVest = 1  # Avoid division by zero\n",
    "                group_df['computedVest'] = np.maximum(group_df['percentVest'] / total_percentVest * total_height, 0.8)\n",
    "        \n",
    "        # Identify distinct combos within this group\n",
    "        # Step 1: Create a unique schedule for each metric\n",
    "        # Convert schedule into a tuple set per metric\n",
    "        schedule_dict = {}\n",
    "        for metric, group in group_df.groupby('metric_absrel'):\n",
    "            unique_schedule = group[['grantDate', 'startDate', 'endDate']].drop_duplicates()\n",
    "            schedule = tuple(unique_schedule.apply(tuple, axis=1))\n",
    "            schedule_dict[metric] = schedule\n",
    "        \n",
    "        # Step 2: Group metrics by identical schedules\n",
    "        schedule_to_metrics = {}\n",
    "        for metric, schedule in schedule_dict.items():\n",
    "            if schedule in schedule_to_metrics:\n",
    "                schedule_to_metrics[schedule].append(metric)\n",
    "            else:\n",
    "                schedule_to_metrics[schedule] = [metric]\n",
    "        \n",
    "        # Step 3: Assign group labels to metrics\n",
    "        metric_to_group = {}\n",
    "        for group_idx, (schedule, metrics) in enumerate(schedule_to_metrics.items(), start=1):\n",
    "            for metric in metrics:\n",
    "                metric_to_group[metric] = f\"Group_{group_idx}\"\n",
    "        \n",
    "        # Step 4: Add group information back to the original DataFrame\n",
    "        group_df = group_df.copy()\n",
    "        group_df['metric_group'] = group_df['metric_absrel'].map(metric_to_group)\n",
    "        # print(group_df)\n",
    "\n",
    "        further_groups = group_df.groupby(['metric_group'], dropna=False)\n",
    "        \n",
    "        # If only 1 distinct timeline, we label the y-axis with all metrics from the entire group\n",
    "        # else, we label each timeline line with its metrics\n",
    "        if len(further_groups) == 1:\n",
    "            \n",
    "            # print(grant_id,1)\n",
    "            # There's just one combo => we can directly get that\n",
    "            metric_group, metric_df = list(further_groups)[0]\n",
    "            combo_groups = metric_df.groupby(['grantDate', 'startDate', 'endDate'], dropna=False)\n",
    "\n",
    "            sorted_metrics = list(set(metric_df['metric'].tolist()[::-1]))\n",
    "            metric_label = \", \".join(sorted_metrics) if sorted_metrics else \"No Metric\"\n",
    "\n",
    "            grant_text = widgets.HTML(\n",
    "                f\"<b>Grant ID:</b> {grant_id} <br>\"\n",
    "                f\"<b>Grouping:</b> {performance_grouping} <br>\"\n",
    "                f\"<b>Metrics:</b>\"\n",
    "            )\n",
    "            intro_widgets.append(grant_text)\n",
    "\n",
    "            metric_buttons = [\n",
    "                widgets.Button(description=metric, layout=widgets.Layout(width=\"auto\"))\n",
    "                for metric in sorted_metrics\n",
    "            ]\n",
    "\n",
    "            for btn in metric_buttons:\n",
    "                btn.on_click(on_metric_button_click)\n",
    "            # Step 3: Arrange text + buttons horizontally\n",
    "            button_box = widgets.HBox(metric_buttons)  # Display buttons in one row\n",
    "            intro_widgets.append(button_box)  # Add button box to the list\n",
    "\n",
    "\n",
    "            current_y += 6\n",
    "            base_y = current_y\n",
    "            \n",
    "            for (gDate, sDate, eDate), sub_df in combo_groups:\n",
    "                # Plot one line\n",
    "                if novalue:\n",
    "                    # print(grant_id,'novalue')\n",
    "                    color = color_map.get(row['absRel'], 'gray')\n",
    "                    ax.hlines(\n",
    "                        y=current_y,\n",
    "                        xmin=sDate,\n",
    "                        xmax=eDate,\n",
    "                        color=color,\n",
    "                        linestyle=\"dashed\",\n",
    "                        linewidth=1.5  # Adjust thickness of dashed line\n",
    "                    )\n",
    "                    ax.scatter(gDate, current_y, color='black', marker='o', s=20, label=\"Grant Date\" if not legend_labels['Grant Date'] else \"\", zorder=5)\n",
    "                    legend_labels['Grant Date'] = True\n",
    "                else:\n",
    "                    sub_df = sub_df.sort_values(by=['absRel', 'computedVest'], ascending=[False, True])\n",
    "                    # 3) Compute the vertical stacking based on computedVest\n",
    "                    start_y = current_y\n",
    "                    for _, row in sub_df.iterrows():\n",
    "                        height = row['computedVest']\n",
    "                        color = color_map.get(row['absRel'], 'gray')\n",
    "        \n",
    "                        line_label = 'absolute, performance period' if row['absRel'] == 'abs' else 'relative, performance period'\n",
    "\n",
    "                        # print(grant_id,metric,sDate,eDate,start_y)\n",
    "                        # Create a rectangle patch instead of using `ax.plot`\n",
    "                        rect = patches.Rectangle(\n",
    "                            (sDate, start_y),  # (x, y) position\n",
    "                            eDate - sDate,  # width\n",
    "                            height,  # height in data units\n",
    "                            facecolor=color,\n",
    "                            edgecolor=None,  # Optional: add border for better visibility\n",
    "                            linewidth=0.2,  # Keep a thin border\n",
    "                            label=line_label if not legend_labels[line_label] else None\n",
    "                        )\n",
    "                        \n",
    "                        ax.add_patch(rect)  # Add rectangle to the plot\n",
    "        \n",
    "                        # Draw a dashed line between stacked rectangles (except for the last one)\n",
    "                        if _ != sub_df.index[-1]:  \n",
    "                            ax.hlines(\n",
    "                                y=start_y + height,  # Position at top of current rectangle\n",
    "                                xmin=sDate,\n",
    "                                xmax=eDate,\n",
    "                                color=\"white\",\n",
    "                                linestyle=\"dashed\",\n",
    "                                linewidth=0.5  # Adjust thickness of dashed line\n",
    "                            )\n",
    "        \n",
    "                        \n",
    "                        legend_labels[line_label] = True  # Mark legend entry as used\n",
    "                \n",
    "                        # Move up to stack the next segment\n",
    "                        start_y += height  # Ensure consistent stacking in data units\n",
    "                \n",
    "                    # Plot the grant date marker\n",
    "                    ax.scatter(gDate, (current_y + start_y) / 2, color='black', marker='o', s=6, label=\"Grant Date\" if not legend_labels['Grant Date'] else \"\", zorder=5)\n",
    "                    legend_labels['Grant Date'] = True\n",
    "                    current_y = start_y+3\n",
    "    \n",
    "            # We'll label the entire group's y-tick with the list of metrics\n",
    "            y_positions.append((base_y+ current_y)/2)\n",
    "            y_labels.append(f\"{label_for_group}\")\n",
    "\n",
    "            current_y += 6\n",
    "        \n",
    "        else:\n",
    "            # print(grant_id,0)\n",
    "            # Multiple distinct combos => each timeline gets its own line\n",
    "            # We'll label each line with the relevant metrics\n",
    "            lines_in_group = 0\n",
    "            current_y += 6\n",
    "            count = 0\n",
    "            grant_text = widgets.HTML(\n",
    "                f\"<b>Grant ID:</b> {grant_id} <br>\"\n",
    "                f\"<b>Grouping:</b> {performance_grouping} <br>\"\n",
    "            )\n",
    "            intro_widgets.append(grant_text)\n",
    "            \n",
    "            for metric_group, metric_df in further_groups:\n",
    "                base_y = current_y\n",
    "                count += 1\n",
    "                if count >1:\n",
    "                    current_y += 6\n",
    "                    ax.axhline(y=current_y, color='gray', linestyle='dashed', alpha=0.3)\n",
    "                    current_y += 6\n",
    "                base_y = current_y\n",
    "                    \n",
    "                combo_groups = metric_df.groupby(['grantDate', 'startDate', 'endDate'], dropna=False)\n",
    "\n",
    "                sorted_metrics = list(set(metric_df['metric'].tolist()[::-1]))\n",
    "                \n",
    "                metric_label = \", \".join(sorted_metrics) if sorted_metrics else \"No Metric\"\n",
    "    \n",
    "                grant_text = widgets.HTML(\n",
    "                    f\"<b>Metrics:</b>\"\n",
    "                )\n",
    "                intro_widgets.append(grant_text)\n",
    "                metric_buttons = [\n",
    "                    widgets.Button(description=metric, layout=widgets.Layout(width=\"auto\"))\n",
    "                    for metric in sorted_metrics\n",
    "                ]\n",
    "                for btn in metric_buttons:\n",
    "                    btn.on_click(on_metric_button_click)\n",
    "        \n",
    "                # Step 3: Arrange text + buttons horizontally\n",
    "                button_box = widgets.HBox(metric_buttons)  # Display buttons in one row\n",
    "                intro_widgets.append(button_box)  # Add button box to the list\n",
    "\n",
    "                for (gDate, sDate, eDate), sub_df in combo_groups:\n",
    "                    # Plot one line\n",
    "                    if novalue:\n",
    "                        color = color_map.get(row['absRel'], 'gray')\n",
    "                        ax.hlines(\n",
    "                            y=current_y,\n",
    "                            xmin=sDate,\n",
    "                            xmax=eDate,\n",
    "                            color=color,\n",
    "                            linestyle=\"dashed\",\n",
    "                            linewidth=1.5  # Adjust thickness of dashed line\n",
    "                        )\n",
    "                        ax.scatter(gDate, current_y, color='black', marker='o', s=20, label=\"Grant Date\" if not legend_labels['Grant Date'] else \"\", zorder=5)\n",
    "                        legend_labels['Grant Date'] = True\n",
    "                    else:\n",
    "                        sub_df = sub_df.sort_values(by=['absRel', 'computedVest'], ascending=[False, True])\n",
    "                        # 3) Compute the vertical stacking based on computedVest\n",
    "                        start_y = current_y\n",
    "                        for _, row in sub_df.iterrows():\n",
    "                            height = row['computedVest']\n",
    "                            color = color_map.get(row['absRel'], 'gray')\n",
    "            \n",
    "                            line_label = 'absolute, performance period' if row['absRel'] == 'abs' else 'relative, performance period'\n",
    "            \n",
    "                            # Create a rectangle patch instead of using `ax.plot'\n",
    "                            rect = patches.Rectangle(\n",
    "                                (sDate, start_y),  # (x, y) position\n",
    "                                eDate - sDate,  # width\n",
    "                                height,  # height in data units\n",
    "                                facecolor=color,\n",
    "                                edgecolor=None,  # Optional: add border for better visibility\n",
    "                                linewidth=0.2,  # Keep a thin border\n",
    "                                label=line_label if not legend_labels[line_label] else None\n",
    "                            )\n",
    "                            \n",
    "                            ax.add_patch(rect)  # Add rectangle to the plot\n",
    "            \n",
    "                            # Draw a dashed line between stacked rectangles (except for the last one)\n",
    "                            if _ != sub_df.index[-1]:\n",
    "                                ax.hlines(\n",
    "                                    y=start_y + height,  # Position at top of current rectangle\n",
    "                                    xmin=sDate,\n",
    "                                    xmax=eDate,\n",
    "                                    color=\"white\",\n",
    "                                    linestyle=\"dashed\",\n",
    "                                    linewidth=0.5  # Adjust thickness of dashed line\n",
    "                                )\n",
    "            \n",
    "                            \n",
    "                            legend_labels[line_label] = True  # Mark legend entry as used\n",
    "                    \n",
    "                            # Move up to stack the next segment\n",
    "                            start_y += height  # Ensure consistent stacking in data units\n",
    "                    \n",
    "                        # Plot the grant date marker\n",
    "                        ax.scatter(gDate, (current_y + start_y) / 2, color='black', marker='o', s=6, label=\"Grant Date\" if not legend_labels['Grant Date'] else \"\", zorder=5)\n",
    "                        legend_labels['Grant Date'] = True\n",
    "                        current_y = start_y+3\n",
    "                        \n",
    "                # We'll label the entire group's y-tick with the list of metrics\n",
    "                y_positions.append((base_y+ current_y)/2)\n",
    "                y_labels.append(f\"{label_for_group}({count})\")\n",
    "    \n",
    "            current_y += 6\n",
    "\n",
    "        award = grant.loc[grant['grantID'] == grant_id, 'AwardType'].iloc[0] if not grant.loc[grant['grantID'] == grant_id, 'AwardType'].empty else None\n",
    "        color = award_color_map.get(award, 'white')\n",
    "        label = award_label_map.get(award, 'Cash Award')\n",
    "        ax.axhspan(low, current_y, color=color, alpha=1, zorder=-1, label=label)\n",
    "        legend_labels[label] = True\n",
    "        \n",
    "\n",
    "    # Decorate axes\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    ax.set_ylabel(\"Grant-level grouping\")\n",
    "\n",
    "    # Format x-axis as Year-Month\n",
    "    ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "    ax.xaxis.set_minor_locator(mdates.MonthLocator())\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # y-ticks\n",
    "    ax.set_yticks(y_positions + [time_y, option_y, stock_y, base_salary_y])\n",
    "    ax.set_yticklabels(y_labels + [\"Time-Based Awards\", \"Option Awards\", \"Stock Awards\", \"Base Salary\"])\n",
    "\n",
    "    ax.grid(axis='x', linestyle='--', alpha=0.6)\n",
    "\n",
    "    # --- Ensure Proper Legend ---\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    desired_order = ['absolute, performance period', 'relative, performance period', 'Grant Date', 'Non-performance-based', 'Time-based', 'Stock Award','Cash Award','Option Award']\n",
    "    final_labels = [lbl for lbl in desired_order if legend_labels.get(lbl, False)]\n",
    "    # Replace the handle for \"Cash Award\" with a custom one (with a black border)\n",
    "    custom_handles = []\n",
    "    for lbl in final_labels:\n",
    "        if lbl == 'Cash Award':  # Override existing \"Cash Award\" entry\n",
    "            custom_handles.append(patches.Patch(facecolor='white', edgecolor='black', label='Cash Award'))\n",
    "        else:\n",
    "            custom_handles.append(handles[labels.index(lbl)])\n",
    "    # ax.legend(\n",
    "    #     ordered_handles, final_labels, \n",
    "    #     loc='upper center',  # Places legend at the top center\n",
    "    #     bbox_to_anchor=(0.5, 1.15),  # Moves it above the plot\n",
    "    #     ncol=len(final_labels),  # Spread items in a single row\n",
    "    #     frameon=False  # Optional: Remove legend border\n",
    "    # )\n",
    "    # Create the legend above the graph without shrinking it\n",
    "    fig.subplots_adjust(top=0.8)  # Increase top margin without shrinking the plot\n",
    "    \n",
    "    # Add legend as a separate figure element\n",
    "    fig.legend(\n",
    "        custom_handles, final_labels,\n",
    "        loc='upper center',  # Place the legend at the top center\n",
    "        bbox_to_anchor=(0.5, 1.05),  # Position it above the graph\n",
    "        ncol=len(final_labels),  # Arrange items in one row\n",
    "        frameon=False  # Remove legend border\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.title(f\"Grant-Level Timeline for {df_combined['companyName'].iloc[0]}, CEO {participant_dict[participantid]}\")\n",
    "    plt.show()\n",
    "    grant_intro_box.children = tuple(intro_widgets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "39161142-fe96-4f70-b8c9-87967ba0f262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6946077557343129439cbe6be24e2a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<h1 style='text-align: center;'>Visualizing CEO Compensation</h1>\"), HBox(children=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create an Output widget to capture logs\n",
    "error_output = widgets.Output()\n",
    "output_area = widgets.Output()\n",
    "button_container = widgets.HBox()\n",
    "\n",
    "# Placeholder dictionary to store generated plots for each participant\n",
    "graph_store = {}\n",
    "\n",
    "def filter_company_names(substring):\n",
    "    \"\"\"Return a list of company names containing 'substring' (case-insensitive).\"\"\"\n",
    "    s_lower = substring.lower()\n",
    "    return [n for n in all_company_names if s_lower in n.lower()]\n",
    "\n",
    "def on_company_typed(change):\n",
    "    if change['name'] == 'value':\n",
    "        typed = change['new'].strip()  # Remove extra whitespace\n",
    "        # Filter company suggestions\n",
    "        company_widget.options = [n for n in all_company_names if typed.lower() in n.lower()]\n",
    "\n",
    "        # Enable button only if the exact company name is in all_company_names\n",
    "        run_button.disabled = typed not in all_company_names\n",
    "\n",
    "        # If typed is an exact known name => narrow CIK options\n",
    "        if typed in all_company_names:\n",
    "            matched_ciks = ciks_for_company(typed)\n",
    "            CIK_widget.options = matched_ciks\n",
    "\n",
    "            # If the current typed CIK isn't in matched_ciks, clear the CIK\n",
    "            if CIK_widget.value not in matched_ciks:\n",
    "                CIK_widget.value = \"\"\n",
    "        else:\n",
    "            CIK_widget.options = []\n",
    "            CIK_widget.value = \"\"\n",
    "            \n",
    "def on_run_button_click(b):\n",
    "    \"\"\"\n",
    "    Clears the output area, then runs the plotting function.\n",
    "    \"\"\"\n",
    "    with error_output:\n",
    "        error_output.clear_output()  # Clear previous messages\n",
    "        \n",
    "        company_val = company_widget.value\n",
    "\n",
    "        if company_val not in all_company_names:\n",
    "            print(\"Invalid company name\")  # Display error message\n",
    "            return  # Stop execution\n",
    "\n",
    "        with output_area:\n",
    "            output_area.clear_output()\n",
    "        \n",
    "        # Now call your timeline function(s)\n",
    "        participant_list = get_participants_for_company(company_val)\n",
    "\n",
    "        # Clear previous buttons\n",
    "        button_container.children = []\n",
    "    \n",
    "        # Create buttons for each CEO\n",
    "        buttons = [\n",
    "            widgets.Button(description=f\"{participant_dict[participant]}\", layout=widgets.Layout(width=\"200px\", height=\"auto\", overflow=\"visible\"))\n",
    "            for participant in participant_list\n",
    "        ]\n",
    "\n",
    "        # Attach event handlers\n",
    "        for btn, participant in zip(buttons, participant_list):\n",
    "            btn.on_click(lambda b, p=participant: plot_selected_graph(company_val, p))\n",
    "    \n",
    "        # Display buttons\n",
    "        button_container.children = buttons\n",
    "\n",
    "def plot_selected_graph(company_val, participant_val):\n",
    "    \"\"\"\n",
    "    Clears the output area and plots the graph for the selected CEO.\n",
    "    \"\"\"\n",
    "    with output_area:\n",
    "        output_area.clear_output(wait=True)\n",
    "        plot_compensation_timeline_by_grant(company_val, participant_val, False)\n",
    "\n",
    "def on_metric_button_click(b):\n",
    "    with metric_output:  # Direct output to the output widget\n",
    "        metric_output.clear_output()\n",
    "        print(f\"The pay-performance relationship for metric: {b.description}\")\n",
    "\n",
    "# --- Create dynamic Comboboxes for Company & CIK ---\n",
    "company_widget = widgets.Combobox(\n",
    "    placeholder='Type a company name...',\n",
    "    options=all_company_names,\n",
    "    description='Company:'\n",
    ")\n",
    "company_widget.value = \"Citigroup INC\"  # your existing default\n",
    "company_widget.observe(on_company_typed, names='value')\n",
    "\n",
    "run_button = widgets.Button(description=\"Generate Timeline\")\n",
    "output_area = widgets.Output()\n",
    "\n",
    "# Create a title widget\n",
    "title_widget = widgets.HTML(\n",
    "    value=\"<h1 style='text-align: center;'>Visualizing CEO Compensation</h1>\"\n",
    ")\n",
    "\n",
    "run_button.on_click(on_run_button_click)\n",
    "\n",
    "# Create the Clear button\n",
    "clear_button = widgets.Button(description=\"Clear\", button_style='warning')\n",
    "\n",
    "# Function to clear input fields\n",
    "def on_clear_button_click(b):\n",
    "    company_widget.value = \"\"\n",
    "\n",
    "# Attach event to Clear button\n",
    "clear_button.on_click(on_clear_button_click)\n",
    "grant_intro_box = widgets.VBox([])\n",
    "\n",
    "metric_output = widgets.Output()\n",
    "\n",
    "# Display the widgets & output in the notebook\n",
    "display(\n",
    "    widgets.VBox([\n",
    "        title_widget,  # Add the title at the top\n",
    "        widgets.HBox([company_widget]),\n",
    "        widgets.HBox([run_button, clear_button]),\n",
    "        error_output,\n",
    "        button_container,\n",
    "        output_area,\n",
    "        metric_output,\n",
    "        grant_intro_box\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a360a4b-5a8b-4bb4-be2c-80577c4b73de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92f0ad7-f5eb-48e1-a2c1-d969a7371f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
