{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bf58a27-b4cb-4c8b-87f7-879e237fb2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### loading the packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.patches as patches\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import voila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35249c1e-13e9-4d12-a981-9cd818c92f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of a global directory, just use relative folders:\n",
    "# os.chdir(\"/Users/ruofeiguo/CEO Compensation/my-timeline-repo\")\n",
    "data_directory = \"data\"\n",
    "# graph_directory = \"graph\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b543138-796e-4954-b0b5-428bd7a06242",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = pd.read_csv(os.path.join(data_directory, 'SumComp.csv'))\n",
    "base['CIK'] = base['CIK'].astype(str).str.replace(r\"[^\\d]\", \"\", regex=True).astype(int)\n",
    "# # base.to_csv(os.path.join(data_directory, 'SumComp.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9cb88355-b165-4e64-b019-eda84641bd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "grant = pd.read_csv(os.path.join(data_directory, 'GpbaGrant_clean.csv'))\n",
    "# grant = grant[['grantID', 'performanceGrouping']]\n",
    "# grant.to_csv(os.path.join(data_directory, 'GpbaGrant_clean.csv'), index=False)\n",
    "# print(grant.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4f6cec4-1573-4a50-a883-0e1232a60d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp = pd.read_csv(os.path.join(data_directory, 'GpbaAbs_vest_clean.csv'), encoding=\"latin1\")\n",
    "\n",
    "company_list = (\n",
    "    df_comp[['CIK', 'companyName']]\n",
    "    .drop_duplicates()\n",
    "    .values\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "df_comp['participantid'] = df_comp['participantid'].astype(int)\n",
    "ceo_list = (\n",
    "    df_comp[['CIK', 'participantid']]\n",
    "    .drop_duplicates()\n",
    "    .values\n",
    "    .tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df01cf53-3856-4c56-9af5-b21eb34e532d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_combined(company_name=None, CIK=None, participantid=None, dis=False):\n",
    "    \"\"\"\n",
    "    Reads the CSV files, filters on company_name (substring match, case-insensitive),\n",
    "    CIK, and participantid if they are provided. Returns the combined DataFrame with\n",
    "    columns: [CIK, companyName, metric, fiscalYear, grantDate, startDate, endDate, value, absRel].\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Read CSVs ---\n",
    "    df_abs = pd.read_csv(os.path.join(data_directory, 'GpbaAbs_vest_clean.csv'))\n",
    "    df_rel = pd.read_csv(os.path.join(data_directory, 'GpbaRel_vest.csv'))\n",
    "\n",
    "    # --- Filter the DataFrames ---\n",
    "    if company_name:\n",
    "        df_abs_filtered = df_abs[(df_abs['companyName'].str.contains(company_name, case=False, na=False))& (df_abs['participantid'] == float(participantid))]\n",
    "        df_rel_filtered = df_rel[(df_rel['companyName'].str.contains(company_name, case=False, na=False))& (df_rel['participantid'] == float(participantid))]\n",
    "    else:\n",
    "        df_abs_filtered = df_abs[(df_abs['CIK'] == CIK) & (df_abs['participantid'] == float(participantid))]\n",
    "        df_rel_filtered = df_rel[(df_rel['CIK'] == CIK) & (df_rel['participantid'] == float(participantid))]\n",
    "\n",
    "    if df_abs_filtered.empty and df_rel_filtered.empty:\n",
    "        print(f\"No data found for CIK={CIK}, participant={participantid}.\")\n",
    "        return  # nothing else to plot\n",
    "    \n",
    "    # --- Select columns and label abs/rel ---\n",
    "    columns_to_display = [\n",
    "        'CIK', 'companyName', 'metric', 'fiscalYear', \n",
    "        'grantDate', 'startDate', 'endDate', 'size', 'percentVest', 'value', 'grantId'\n",
    "    ]\n",
    "    df_abs_filtered = df_abs_filtered[columns_to_display].copy()\n",
    "    df_rel_filtered = df_rel_filtered[columns_to_display].copy()\n",
    "\n",
    "    df_abs_filtered['absRel'] = 'abs'\n",
    "    df_rel_filtered['absRel'] = 'rel'\n",
    "\n",
    "    df_combined = pd.concat([df_abs_filtered, df_rel_filtered], ignore_index=True)\n",
    "    df_combined = df_combined.sort_values(by=['metric', 'grantDate'], ascending=[True, True])\n",
    "\n",
    "    # Display the combined DataFrame (in notebook)\n",
    "    if dis:\n",
    "        display(df_combined)\n",
    "\n",
    "    return df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64596096-049a-4e5c-b78d-bddebaa30c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_compensation_timeline_by_grant(company_name, CIK, participantid, dis=False):\n",
    "    \"\"\"\n",
    "    Group df_combined by 'grantId'. \n",
    "    For each group, determine distinct (grantDate, startDate, endDate) combos.\n",
    "    Plot one horizontal line per distinct combo. \n",
    "    Label the y-axis with:\n",
    "      - if there's only one distinct timeline, show the list of metrics in the group\n",
    "      - if multiple timelines exist, show separate lines, labeling each line with the relevant metrics\n",
    "    \"\"\"\n",
    "    df_combined = create_df_combined(company_name=company_name, CIK=CIK, participantid=participantid, dis=dis)\n",
    "    if df_combined.empty:\n",
    "        print(f\"No data found for company={company_name}, CIK={CIK}, participant={participantid}.\")\n",
    "        return\n",
    "\n",
    "    # Just in case, ensure these are datetimes\n",
    "    df_combined['grantDate'] = pd.to_datetime(df_combined['grantDate'], errors='coerce')\n",
    "    df_combined['startDate'] = pd.to_datetime(df_combined['startDate'], errors='coerce')\n",
    "    df_combined['endDate']   = pd.to_datetime(df_combined['endDate'], errors='coerce')\n",
    "\n",
    "    # --- Retrieve base salary data ---\n",
    "    if pd.isna(CIK):  # If company_name is used, map it to CIK\n",
    "        CIK = df_combined['CIK'].iloc[0] if not df_combined.empty else None\n",
    "\n",
    "    base_filtered = base[(base['CIK'] == CIK) & (base['participantid'] == int(participantid))]\n",
    "\n",
    "    # Convert fiscalYear to integer for sorting\n",
    "    base_filtered.loc[:,'FiscalYear'] = pd.to_numeric(base_filtered['FiscalYear'], errors='coerce')\n",
    "    \n",
    "    # --- Compute the minimum value for scaling line thickness ---\n",
    "    max_value = pd.concat([df_combined['size'], base_filtered['salary'], base_filtered['stockAwards']], axis=0).dropna().max()\n",
    "\n",
    "    # Group by grantId\n",
    "    grouped = df_combined.groupby('grantId', dropna=False)\n",
    "    group_grant_dates = {grantId: sub_df['grantDate'].min() for grantId, sub_df in grouped}\n",
    "    sorted_groups = sorted(group_grant_dates.items(), key=lambda x: x[1])\n",
    "\n",
    "    # Prepare the figure\n",
    "    fig_width = 12  # Keep a fixed width\n",
    "    fig_height = max(6, (len(grouped)+1) * 0.5)  # Scale height based on number of items\n",
    "    fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "\n",
    "    # For coloring, reuse your color scheme if you want\n",
    "    palette = sns.color_palette(\"colorblind\", 10)\n",
    "    color_map = {'abs': palette[0], 'rel': palette[1]}\n",
    "    \n",
    "    # We'll keep track of the y-position for each group\n",
    "    current_y = 10\n",
    "    y_positions = []\n",
    "    y_labels = []\n",
    "\n",
    "    # Track legend entries\n",
    "    legend_labels = {\n",
    "        'absolute, performance period': False,\n",
    "        'relative, performance period': False,\n",
    "        'Grant Date': False,\n",
    "        'Non-performance-based': False\n",
    "    }\n",
    "\n",
    "    # --- Plot Base Salary ---\n",
    "    max_salary_award = 0 if base_filtered['salary'].dropna().empty else max(20 * base_filtered['salary'].dropna().max() / max_value, 0.3)\n",
    "    max_stock_award = 0 if base_filtered['stockAwards'].dropna().empty else max(20 * base_filtered['stockAwards'].dropna().max() / max_value, 0.3)\n",
    "    max_option_award = 0 if base_filtered['optionAwards'].dropna().empty else max(20 * base_filtered['optionAwards'].dropna().max() / max_value, 0.3)\n",
    "    base_salary_y = current_y\n",
    "    stock_y = base_salary_y + max_salary_award/2 + 4 + max_stock_award/2\n",
    "    option_y = stock_y + max_stock_award/2 + 4 + max_option_award/2\n",
    "    ax.axhline(y=base_salary_y + max_salary_award/2 + 2, color='gray', linestyle='dashed', alpha=0.3)\n",
    "    ax.axhline(y=stock_y + max_stock_award/2 + 2, color='gray', linestyle='dashed', alpha=0.3)\n",
    "    for _, row in base_filtered.iterrows():\n",
    "        fiscal_year = int(row['FiscalYear'])\n",
    "        salary_value = row['salary']\n",
    "        salary_height = 0\n",
    "        if pd.notna(salary_value):\n",
    "            height = max(20 * salary_value / max_value, 1)\n",
    "            # Create a rectangle for base salary\n",
    "            base_salary_rect = patches.Rectangle(\n",
    "                (pd.Timestamp(f\"{fiscal_year}-01-01\"), base_salary_y - height / 2),  # (x, y) position\n",
    "                pd.Timedelta(days=365),  # Width covering the full year\n",
    "                height,  # Height scaled to salary value\n",
    "                color='black',\n",
    "                label='Non-performance-based'\n",
    "            )\n",
    "            \n",
    "            ax.add_patch(base_salary_rect)  # Add rectangle to the plot\n",
    "\n",
    "            legend_labels['Non-performance-based'] = True\n",
    "\n",
    "        stock_value = row['stockAwards']\n",
    "        if pd.notna(stock_value):\n",
    "            height = max(20 * stock_value / max_value, 1)\n",
    "            # Create a rectangle for base salary\n",
    "            stock_rect = patches.Rectangle(\n",
    "                (pd.Timestamp(f\"{fiscal_year}-01-01\"), stock_y - height / 2),  # (x, y) position\n",
    "                pd.Timedelta(days=365),  # Width covering the full year\n",
    "                height,  # Height scaled to salary value\n",
    "                color='black',\n",
    "                label='Non-performance-based'\n",
    "            )\n",
    "            \n",
    "            ax.add_patch(stock_rect)  # Add rectangle to the plot\n",
    "            legend_labels['Non-performance-based'] = True\n",
    "\n",
    "        option_value = row['optionAwards']\n",
    "        if pd.notna(option_value):\n",
    "            height = max(20 * option_value / max_value, 1)\n",
    "            # Create a rectangle for base salary\n",
    "            option_rect = patches.Rectangle(\n",
    "                (pd.Timestamp(f\"{fiscal_year}-01-01\"), option_y - height / 2),  # (x, y) position\n",
    "                pd.Timedelta(days=365),  # Width covering the full year\n",
    "                height,  # Height scaled to salary value\n",
    "                color='black',\n",
    "                label='Non-performance-based'\n",
    "            )\n",
    "            \n",
    "            ax.add_patch(option_rect)  # Add rectangle to the plot\n",
    "            legend_labels['Non-performance-based'] = True\n",
    "\n",
    "    current_y = option_y + max_option_award/2 + 2\n",
    "    sorted_grant_ids = sorted(grouped.groups.keys(), key=lambda x: group_grant_dates[x])\n",
    "\n",
    "    for grant_id in sorted_grant_ids:\n",
    "        ax.axhline(y=current_y, color='gray', linestyle='dashed', alpha=0.3)\n",
    "        # old_y = current_y\n",
    "        group_df = grouped.get_group(grant_id)  # Retrieve the actual DataFrame\n",
    "        label_for_group = f\"GrantID={grant_id}\" if pd.notna(grant_id) else \"Unknown GrantId\"\n",
    "\n",
    "        # Identify distinct combos within this group\n",
    "        combo_groups = group_df.groupby(['grantDate', 'startDate', 'endDate'], dropna=False)\n",
    "        \n",
    "        # If only 1 distinct timeline, we label the y-axis with all metrics from the entire group\n",
    "        # else, we label each timeline line with its metrics\n",
    "        if len(combo_groups) == 1:\n",
    "            # There's just one combo => we can directly get that\n",
    "            (gDate, sDate, eDate), sub_df = list(combo_groups)[0]\n",
    "            \n",
    "            # Plot one line\n",
    "            first_value = sub_df['value'].iloc[0] if not sub_df['value'].isna().all() else max_value\n",
    "            total_height = max(20 * (first_value / max_value) if max_value else 20,1)\n",
    "            # 1) Check if percentVest has NaNs\n",
    "            if sub_df['percentVest'].isna().any():\n",
    "                use_count_based = True\n",
    "                total_count = len(sub_df)\n",
    "                sub_df['computedVest'] = total_height / total_count  # Equal height for all rows\n",
    "                # linestyle = 'o'  # Dashed lines since we are using fallback\n",
    "            else:\n",
    "                use_count_based = False\n",
    "                total_percentVest = sub_df['percentVest'].sum()\n",
    "                if total_percentVest == 0 or pd.isna(total_percentVest):\n",
    "                    total_percentVest = 1  # Avoid division by zero\n",
    "                sub_df['computedVest'] = sub_df['percentVest'] / total_percentVest * total_height\n",
    "                # linestyle = None  # Solid lines for percent-based stacking\n",
    "        \n",
    "            # 2) Sort by 'absRel' (absolute first, then relative), then by height (largest to smallest)\n",
    "            sub_df = sub_df.sort_values(by=['absRel', 'computedVest'], ascending=[False, True])\n",
    "            sorted_metrics = sub_df['metric'].tolist()[::-1]  # Get metric names in the same order as stacks\n",
    "            metric_label = \", \".join(sorted_metrics[:2]) + (\"...\" if len(sorted_metrics) > 3 else \"\") if sorted_metrics else \"No Metric\"\n",
    "            \n",
    "            # 3) Compute the vertical stacking based on computedVest\n",
    "            current_y += 1 if total_height>15 else (8-total_height/2)\n",
    "            start_y = current_y\n",
    "            for _, row in sub_df.iterrows():\n",
    "                height = row['computedVest']\n",
    "                color = color_map.get(row['absRel'], 'gray')\n",
    "\n",
    "                line_label = 'absolute, performance period' if row['absRel'] == 'abs' else 'relative, performance period'\n",
    "\n",
    "                # Create a rectangle patch instead of using `ax.plot`\n",
    "                rect = patches.Rectangle(\n",
    "                    (sDate, start_y),  # (x, y) position\n",
    "                    eDate - sDate,  # width\n",
    "                    height,  # height in data units\n",
    "                    facecolor=color,\n",
    "                    edgecolor=None,  # Optional: add border for better visibility\n",
    "                    linewidth=0.2,  # Keep a thin border\n",
    "                    label=line_label if not legend_labels[line_label] else None\n",
    "                )\n",
    "                \n",
    "                ax.add_patch(rect)  # Add rectangle to the plot\n",
    "\n",
    "                # Draw a dashed line between stacked rectangles (except for the last one)\n",
    "                if _ != sub_df.index[-1]:  \n",
    "                    ax.hlines(\n",
    "                        y=start_y + height,  # Position at top of current rectangle\n",
    "                        xmin=sDate,\n",
    "                        xmax=eDate,\n",
    "                        color=\"black\",\n",
    "                        linestyle=\"dashed\",\n",
    "                        linewidth=0.5  # Adjust thickness of dashed line\n",
    "                    )\n",
    "\n",
    "            \n",
    "                legend_labels[line_label] = True  # Mark legend entry as used\n",
    "            \n",
    "                # Move up to stack the next segment\n",
    "                start_y += height  # Ensure consistent stacking in data units\n",
    "            \n",
    "            # Plot the grant date marker\n",
    "            ax.scatter(gDate, current_y + total_height / 2, color='black', marker='o', s=20, label=\"Grant Date\" if not legend_labels['Grant Date'] else \"\", zorder=5)\n",
    "            legend_labels['Grant Date'] = True\n",
    "\n",
    "            # We'll label the entire group's y-tick with the list of metrics\n",
    "            y_positions.append(current_y+ total_height/2)\n",
    "            y_labels.append(f\"{label_for_group}\\n({metric_label})\")\n",
    "\n",
    "            current_y += total_height + 1 if total_height>15 else (8+total_height/2)   # move down for next group\n",
    "        \n",
    "        else:\n",
    "            # Multiple distinct combos => each timeline gets its own line\n",
    "            # We'll label each line with the relevant metrics\n",
    "            base_y = current_y\n",
    "            lines_in_group = 0\n",
    "\n",
    "            for (gDate, sDate, eDate), sub_df in combo_groups:\n",
    "                # gather metrics for *this timeline*\n",
    "                first_value = sub_df['value'].iloc[0] if not sub_df['value'].isna().all() else min_value\n",
    "                total_height = max(20 * (first_value / max_value) if max_value else 20,1)\n",
    "                # 1) Check if percentVest has NaNs\n",
    "                if sub_df['percentVest'].isna().any():\n",
    "                    use_count_based = True\n",
    "                    total_count = len(sub_df)\n",
    "                    sub_df['computedVest'] = total_height / total_count  # Equal height for all rows\n",
    "                    # linestyle = '--'  # Dashed lines since we are using fallback\n",
    "                else:\n",
    "                    use_count_based = False\n",
    "                    total_percentVest = sub_df['percentVest'].sum()\n",
    "                    if total_percentVest == 0 or pd.isna(total_percentVest):\n",
    "                        total_percentVest = 1  # Avoid division by zero\n",
    "                    sub_df['computedVest'] = sub_df['percentVest'] / total_percentVest * total_height\n",
    "                    # linestyle = '-'  # Solid lines for percent-based stacking\n",
    "\n",
    "                # 2) Sort by 'absRel' (absolute first, then relative), then by height (largest to smallest)\n",
    "                sub_df = sub_df.sort_values(by=['absRel', 'computedVest'], ascending=[False, True])\n",
    "                sorted_metrics = sub_df['metric'].tolist()[::-1]  # Get metric names in the same order as stacks\n",
    "                metric_label = \", \".join(sorted_metrics) if sorted_metrics else \"No Metric\"\n",
    "            \n",
    "                # 3) Compute the vertical stacking based on computedVest\n",
    "                start_y = current_y\n",
    "                for _, row in sub_df.iterrows():\n",
    "                    height = row['computedVest']\n",
    "                    color = color_map.get(row['absRel'], 'gray')\n",
    "            \n",
    "                    line_label = 'absolute, performance period' if row['absRel'] == 'abs' else 'relative, performance period'\n",
    "\n",
    "                    # Create a rectangle patch instead of using `ax.plot`\n",
    "                    rect = patches.Rectangle(\n",
    "                        (sDate, start_y),  # (x, y) position\n",
    "                        eDate - sDate,  # width\n",
    "                        height,  # height in data units\n",
    "                        facecolor=color,\n",
    "                        # linestyle=linestyle,\n",
    "                        edgecolor='black',  # Optional: add border for better visibility\n",
    "                        linewidth=0.2,  # Keep a thin border\n",
    "                        label=line_label if not legend_labels[line_label] else None\n",
    "                    )\n",
    "                    \n",
    "                    ax.add_patch(rect)  # Add rectangle to the plot\n",
    "                \n",
    "                    legend_labels[line_label] = True  # Mark legend entry as used\n",
    "                \n",
    "                    # Move up to stack the next segment\n",
    "                    start_y += height  # Ensure consistent stacking in data units\n",
    "\n",
    "                # Add a text annotation near the middle of the line with the metrics\n",
    "                mid_x = sDate + (eDate - sDate) / 2 if (pd.notna(sDate) and pd.notna(eDate)) else sDate\n",
    "                ax.text(mid_x, current_y + total_height / 2, metric_label, ha='center', va='bottom', fontsize=9, color='black')\n",
    "\n",
    "                # Plot the grant date marker\n",
    "                ax.scatter(gDate, current_y + total_height / 2, color='black', marker='o', s=20, label=\"Grant Date\" if not legend_labels['Grant Date'] else \"\", zorder=5)\n",
    "                legend_labels['Grant Date'] = True\n",
    "\n",
    "                current_y += total_height + 1\n",
    "                lines_in_group += 1\n",
    "\n",
    "            # after multiple lines, we can label the base_y with the group name\n",
    "            # e.g. put a label at the midpoint of those lines\n",
    "            group_center_y = base_y + (lines_in_group - 1) / 2\n",
    "            y_positions.append(group_center_y)\n",
    "            y_labels.append(label_for_group)\n",
    "            current_y += 1  # blank space between groups\n",
    "\n",
    "    # Decorate axes\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    ax.set_ylabel(\"Grant-level grouping\")\n",
    "\n",
    "    # Format x-axis as Year-Month\n",
    "    ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "    ax.xaxis.set_minor_locator(mdates.MonthLocator())\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # y-ticks\n",
    "    ax.set_yticks(y_positions + [option_y, stock_y, base_salary_y])\n",
    "    ax.set_yticklabels(y_labels + [\"Option Awards\", \"Stock Awards\", \"Base Salary\"])\n",
    "\n",
    "    ax.grid(axis='x', linestyle='--', alpha=0.6)\n",
    "\n",
    "    # --- Ensure Proper Legend ---\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    desired_order = ['absolute, performance period', 'relative, performance period', 'Grant Date', 'Non-performance-based']\n",
    "    final_labels = [lbl for lbl in desired_order if legend_labels.get(lbl, False)]\n",
    "    ordered_handles = [handles[labels.index(lbl)] for lbl in final_labels if lbl in labels]\n",
    "    ax.legend(ordered_handles, final_labels, loc='upper left')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.title(f\"Grant-Level Timeline for {df_combined['companyName'].iloc[0]}, CEO {participantid}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39161142-fe96-4f70-b8c9-87967ba0f262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16b47028419b4203b05154affbfffdbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Combobox(value='Apple INC', description='Company:', options=('21st Century Insurâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build sets of all names, all CIKs:\n",
    "all_company_names = sorted({nm for (_, nm) in company_list})\n",
    "all_ciks = sorted({c for (c, _) in company_list})\n",
    "all_ceos = sorted({p for (_, p) in ceo_list})\n",
    "\n",
    "def filter_company_names(substring):\n",
    "    \"\"\"Return a list of company names containing 'substring' (case-insensitive).\"\"\"\n",
    "    s_lower = substring.lower()\n",
    "    return [n for n in all_company_names if s_lower in n.lower()]\n",
    "\n",
    "def filter_ciks(substring):\n",
    "    \"\"\"Return a list of CIKs (as strings) containing 'substring'.\"\"\"\n",
    "    return [str(c) for c in all_ciks if substring in str(c)]\n",
    "\n",
    "def filter_ceos(substring):\n",
    "    \"\"\"Return a list of CEOs (as strings) containing 'substring'.\"\"\"\n",
    "    return [str(p) for p in all_ceos if substring in str(p)]\n",
    "\n",
    "def ciks_for_company(company_name):\n",
    "    \"\"\"All CIKs that match the given company_name in company_list, as strings.\"\"\"\n",
    "    return sorted({str(c) for (c, n) in company_list if n == company_name})\n",
    "\n",
    "def names_for_cik(cik_str):\n",
    "    \"\"\"All company names that match the given CIK in company_list.\"\"\"\n",
    "    try:\n",
    "        cik_int = int(cik_str)\n",
    "        return sorted({n for (c, n) in company_list if c == cik_int})\n",
    "    except ValueError:\n",
    "        return []\n",
    "\n",
    "def ceos_for_cik(cik_str):\n",
    "    \"\"\"All CEO names that match the given CIK in ceo_list.\"\"\"\n",
    "    try:\n",
    "        cik_int = int(cik_str)\n",
    "        return sorted({str(item[1]) for item in ceo_list if int(item[0]) == cik_int})\n",
    "    except ValueError:\n",
    "        return []\n",
    "\n",
    "\n",
    "# --- Create dynamic Comboboxes for Company & CIK ---\n",
    "company_widget = widgets.Combobox(\n",
    "    placeholder='Type a company name...',\n",
    "    options=all_company_names,\n",
    "    description='Company:'\n",
    ")\n",
    "company_widget.value = \"Apple INC\"  # your existing default\n",
    "\n",
    "CIK_widget = widgets.Combobox(\n",
    "    placeholder='Type a CIK...',\n",
    "    options=[str(c) for c in all_ciks],\n",
    "    description='CIK:'\n",
    ")\n",
    "CIK_widget.value = \"320193\"  # your existing default\n",
    "\n",
    "participant_widget = widgets.Combobox(\n",
    "    placeholder='Type a CEO ID...',\n",
    "    options=[str(p) for p in all_ceos],\n",
    "    description='CEO ID:'\n",
    ")\n",
    "participant_widget.value = \"85682\"  # your existing default\n",
    "\n",
    "run_button = widgets.Button(description=\"Generate Timeline\")\n",
    "output_area = widgets.Output()\n",
    "\n",
    "# Observers for dynamic suggestions:\n",
    "def on_company_typed(change):\n",
    "    if change['name'] == 'value':\n",
    "        typed = change['new'].strip()  # Remove extra whitespace\n",
    "        typed = change['new']\n",
    "        # Filter company suggestions\n",
    "        company_widget.options = [\n",
    "            n for n in all_company_names \n",
    "            if typed.lower() in n.lower()\n",
    "        ]\n",
    "        \n",
    "        # If typed is an exact known name => narrow CIK options\n",
    "        if typed in all_company_names:\n",
    "            # Show only the matched CIK(s)\n",
    "            matched_ciks = ciks_for_company(typed)\n",
    "            CIK_widget.options = matched_ciks\n",
    "\n",
    "            # If the current typed CIK isn't in matched_ciks, clear the CIK\n",
    "            if CIK_widget.value not in matched_ciks:\n",
    "                CIK_widget.value = \"\"  # Clear if mismatch\n",
    "        else:\n",
    "            # Not a finalized name => you could restore full CIK list or partial filter\n",
    "            CIK_widget.options = []\n",
    "            CIK_widget.value = \"\"\n",
    "            pass\n",
    "\n",
    "def on_cik_typed(change):\n",
    "    if change['name'] == 'value':\n",
    "        typed = change['new'].strip()\n",
    "        print(\"CIK typed:\", typed)  # Debug print\n",
    "        # Filter suggestions for CIK\n",
    "        CIK_widget.options = filter_ciks(typed)\n",
    "        known_ciks = [str(c) for c in all_ciks]\n",
    "        # print(\"Known CIKs:\", known_ciks)  # Debug print\n",
    "        \n",
    "        # If typed is exactly one known CIK:\n",
    "        if typed in known_ciks:\n",
    "            # Show only the matched company name(s)\n",
    "            matched_names = names_for_cik(typed)\n",
    "            company_widget.options = matched_names\n",
    "            \n",
    "            matched_ceos = ceos_for_cik(typed)\n",
    "            print(\"Matched CEOs for CIK\", typed, \":\", matched_ceos)  # Debug print\n",
    "            participant_widget.options = matched_ceos\n",
    "\n",
    "            # If the current typed company isn't in matched_names, clear the company\n",
    "            if company_widget.value not in matched_names:\n",
    "                company_widget.value = \"\"\n",
    "            if participant_widget.value not in matched_ceos:\n",
    "                participant_widget.value = \"\"\n",
    "        else:\n",
    "            # Not a finalized CIK => you could restore full name list or partial filter\n",
    "            company_widget.options = []\n",
    "            company_widget.value = \"\"\n",
    "            participant_widget.options = filter_ceos(typed)\n",
    "            participant_widget.value = \"\"\n",
    "\n",
    "company_widget.observe(on_company_typed, names='value')\n",
    "CIK_widget.observe(on_cik_typed, names='value')\n",
    "\n",
    "\n",
    "def on_run_button_click(b):\n",
    "    \"\"\"\n",
    "    Clears the output area, then runs the plotting function.\n",
    "    \"\"\"\n",
    "    with output_area:\n",
    "        output_area.clear_output()\n",
    "        \n",
    "        company_val = company_widget.value\n",
    "        cik_val_str = CIK_widget.value\n",
    "        try:\n",
    "            CIK_val = int(cik_val_str)  # convert typed string to int\n",
    "        except ValueError:\n",
    "            CIK_val = None  # or handle error\n",
    "        participant_val = participant_widget.value\n",
    "\n",
    "        # Now call your timeline function(s)\n",
    "        # plot_compensation_timeline(company_val, CIK_val, participant_val, False)\n",
    "        plot_compensation_timeline_by_grant(company_val, CIK_val, participant_val, True)\n",
    "\n",
    "run_button.on_click(on_run_button_click)\n",
    "\n",
    "# Display the widgets & output in the notebook\n",
    "display(\n",
    "    widgets.VBox([\n",
    "        widgets.HBox([company_widget, CIK_widget, participant_widget]),\n",
    "        run_button,\n",
    "        output_area\n",
    "    ])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a360a4b-5a8b-4bb4-be2c-80577c4b73de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92f0ad7-f5eb-48e1-a2c1-d969a7371f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
